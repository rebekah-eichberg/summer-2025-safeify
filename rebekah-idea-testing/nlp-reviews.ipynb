{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5257000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')       \n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt_tab')  \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import stacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_pickle('reviews_raw.pkl')\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ade651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random asin from the DataFrame\n",
    "reviews_df['asin'].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de661c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df based on the random asin\n",
    "test_df = reviews_df.loc[reviews_df['asin'] == 'B00ICDB1QO'].copy()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6aaa26",
   "metadata": {},
   "source": [
    "need to preprocess the text\n",
    "1. lowercase the text\n",
    "2. remove punctuation and special characters\n",
    "3. tokenize\n",
    "4. stopword removal\n",
    "5. stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i think it might be best to functionize this\n",
    "\n",
    "def preprocess_reviews_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  \n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))  \n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df = test_df.copy()\n",
    "tfid_df['cleaned_text'] = tfid_df['reviewText'].copy().apply(preprocess_reviews_text)\n",
    "tfid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464afd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df['review_length'] = tfid_df['reviewText'].apply(len)\n",
    "tfid_df['word_count'] = tfid_df['reviewText'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958dcc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "tfid_df['sentiment'] = tfid_df['reviewText'].apply(lambda x: sid.polarity_scores(x)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c48ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5)\n",
    "X_tfidf = vectorizer.fit_transform(tfid_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc40415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse matrix\n",
    "temp_df = pd.DataFrame(X_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ded2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df = pd.concat([tfid_df.reset_index(drop=True), temp_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Mean sentiment, average word count, etc.\n",
    "agg_tfid_df = tfid_df.agg({\n",
    "    'review_length': ['mean', 'std'],\n",
    "    'word_count': ['mean'],\n",
    "    'sentiment': ['mean'],\n",
    "    **{col: ['mean'] for col in temp_df.columns}\n",
    "}).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1555ed",
   "metadata": {},
   "source": [
    "spacy time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe509c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_vector(text):\n",
    "    return nlp(text).vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df = test_df.copy()\n",
    "spacy_df['spacy_vector'] = spacy_df['reviewText'].apply(get_spacy_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(spacy_df['spacy_vector'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68cc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(text):\n",
    "    doc = nlp(text)\n",
    "    return {\n",
    "        'word_count': len([t for t in doc if not t.is_punct]),\n",
    "        'noun_count': sum(1 for t in doc if t.pos_ == 'NOUN'),\n",
    "        'verb_count': sum(1 for t in doc if t.pos_ == 'VERB'),\n",
    "        'adj_count': sum(1 for t in doc if t.pos_ == 'ADJ'),\n",
    "        'avg_word_len': np.mean([len(token.text) for token in doc if not token.is_punct]) if len(doc) > 0 else 0,\n",
    "        'sentiment': doc.sentiment  #\n",
    "    }\n",
    "\n",
    "text_feat_df = spacy_df['reviewText'].apply(extract_text_features).apply(pd.Series)\n",
    "spacy_df = pd.concat([spacy_df, text_feat_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7858e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    return sia.polarity_scores(text)['compound']  # Compound is best summary\n",
    "\n",
    "spacy_df['sentiment'] = spacy_df['reviewText'].apply(vader_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a5d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
