{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5257000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')       \n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt_tab')  \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helper_functions import load_clean_csv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8768d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Recall data\n",
    "\n",
    "# Paths to all three files\n",
    "recall_files = [\n",
    "    \"../Data/Current Version of Toys Incidence+Recall/Toysandchildren_ArtsandCrafts.csv\",\n",
    "    \"../Data/Current Version of Toys Incidence+Recall/Toysandchildren_Riding_Toys.csv\",\n",
    "    \"../Data/Current Version of Toys Incidence+Recall/Toysandchildren_Toys.csv\"\n",
    "]\n",
    "\n",
    "recall_dfs = [load_clean_csv(path) for path in recall_files]\n",
    "recalls_df = pd.concat(recall_dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445cbdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624792"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in reviews data\n",
    "reviews_df = pd.read_pickle('reviews_raw.pkl')\n",
    "reviews_df['asin'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fcde81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model to create embeddings on incident description text\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3f5fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the recalls data, embed the incident description\n",
    "incident_desc_embedding = model.encode(recalls_df['Incident Description'].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na in reviewtext, asin and summary column\n",
    "# TODO: should we be dropping duplicates?\n",
    "reviews_model_df = reviews_df[['asin', 'reviewText', 'summary' ,'overall','vote']].copy()\n",
    "reviews_model_df = reviews_model_df.dropna(subset=['asin','reviewText', 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcf59881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip possible leading or trailing white space\n",
    "reviews_model_df = reviews_model_df[reviews_model_df['reviewText'].str.strip() != '']\n",
    "reviews_model_df = reviews_model_df[reviews_model_df['summary'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the reviewsText and summary columns line by line\n",
    "reviews_model_df['reviews_embedding'] = reviews_model_df['reviewText'].apply(lambda x: model.encode(x, show_progress_bar=False))\n",
    "reviews_model_df['summary_embedding'] = reviews_model_df['summary'].apply(lambda x: model.encode(x, show_progress_bar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410732fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate embeddings per ASIN (mean)\n",
    "final_model_df['embedding'] = final_model_df['embedding'].apply(lambda x: np.array(x))\n",
    "asin_embeddings = final_model_df.groupby('asin')['embedding'].apply(lambda x: np.mean(np.stack(x), axis=0)).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac127eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other features to consider\n",
    "# avg_review_length, avg_sentence_count, punctuation_density\n",
    "# capture sentiment like tone or emotion not fully captured in embedding: avg_sentiment_score\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply VADER to each review\n",
    "def get_sentiment_scores(text):\n",
    "    return analyzer.polarity_scores(text)\n",
    "\n",
    "sentiment_df = final_model_df['reviewText'].apply(get_sentiment_scores).apply(pd.Series)\n",
    "\n",
    "# Add to main dataframe\n",
    "final_model_df = pd.concat([final_model_df, sentiment_df], axis=1)\n",
    "\n",
    "# Group by ASIN and aggregate\n",
    "asin_sentiment = final_model_df.groupby('asin')[['compound', 'pos', 'neu', 'neg']].mean().reset_index()\n",
    "\n",
    "# (Optional) Add std deviation if you want:\n",
    "sentiment_std = final_model_df.groupby('asin')['compound'].std().reset_index().rename(columns={'compound': 'compound_std'})\n",
    "asin_sentiment = asin_sentiment.merge(sentiment_std, on='asin', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix_test = pd.merge(asin_embeddings, asin_sentiment, on='asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd4ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4694586    B00WJ1OQC6\n",
       "7550598    B00S0WXWI2\n",
       "4640828    B00VJMDZHS\n",
       "6539636    B005ZI6ZH4\n",
       "4420882    B00SJP73H6\n",
       "Name: asin, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['asin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "79d6f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_asins = ['B00WJ1OQC6','B00S0WXWI2', 'B00VJMDZHS','B005ZI6ZH4', 'B00SJP73H6'  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d1bbab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.loc[reviews_df['asin'].isin(sample_asins)].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576ec59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
