{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893724b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent   \n",
    "sys.path.insert(0, str(project_root / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046d3fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the data\n",
    "train_df = pd.read_parquet(\"../train_final_v3.parquet\")\n",
    "val_df = pd.read_parquet(\"../validationA_v3.parquet\")\n",
    "cal_df = pd.read_parquet(\"../validationB_v3.parquet\")\n",
    "test_df = pd.read_parquet(\"../test_v3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11548ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112768, 791)\n",
      "(24164, 791)\n",
      "(24164, 791)\n",
      "(40274, 791)\n"
     ]
    }
   ],
   "source": [
    "# check shapes of the dataframes\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(cal_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef9233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the target from the features\n",
    "def split_features_target(df, target='match'):\n",
    "    return df.drop(columns=[target]), df[target]\n",
    "\n",
    "X_train, y_train = split_features_target(train_df)\n",
    "X_val, y_val = split_features_target(val_df)\n",
    "X_cal, y_cal = split_features_target(cal_df)\n",
    "X_test, y_test = split_features_target(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa919f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (112768, 785), X_val: (24164, 785), X_cal: (24164, 785), X_test: (40274, 785)\n"
     ]
    }
   ],
   "source": [
    "dfs = [X_train, X_val, X_cal, X_test]\n",
    "\n",
    "for df in dfs:\n",
    "    # Calculate review_span in days\n",
    "    df['review_span'] = (df['max_date'] - df['min_date']).dt.days\n",
    "    df.drop(['min_date', 'max_date'], axis=1, inplace=True)\n",
    "    \n",
    "    # Convert missing_price to int\n",
    "    df['missing_price'] = df['missing_price'].astype(int)\n",
    "    \n",
    "    # Calculate product_lifespan in days\n",
    "    df['product_lifespan_days'] = df['product_lifespan'].dt.days\n",
    "    df.drop('product_lifespan', axis=1, inplace=True)\n",
    "    \n",
    "    df.drop(['percent_positive', 'percent_negative', 'unique_reviewer_count', 'review_span'], axis=1, inplace=True)\n",
    "\n",
    "# Print shapes\n",
    "print(f\"X_train: {X_train.shape}, X_val: {X_val.shape}, X_cal: {X_cal.shape}, X_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910323b",
   "metadata": {},
   "source": [
    "Preprocessing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bcfde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transformer(df,r, s, drop_first=True):\n",
    "    rev_cols  = [c for c in df if c.startswith(\"embedding_\")]\n",
    "    summ_cols = [c for c in df if c.startswith(\"embed_\")]\n",
    "    numeric_cols  = [c for c in df if c not in rev_cols+summ_cols+[\"category\"]]\n",
    "\n",
    "    rev_pipe  = (\"drop\" if r == 0 else Pipeline([(\"scale\",StandardScaler()), (\"pca\",PCA(n_components=r,random_state=42))]))\n",
    "    sum_pipe  = (\"drop\" if s == 0 else Pipeline([(\"scale\",StandardScaler()), (\"pca\",PCA(n_components=s,random_state=42))]))\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        [('num', StandardScaler(), numeric_cols),\n",
    "         ('cat', OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\" if drop_first else None, sparse_output=False), [\"category\"]),\n",
    "         ('rev', rev_pipe,  rev_cols),\n",
    "         ('sum', sum_pipe,  summ_cols)\n",
    "        ]).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d549704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all of the data \n",
    "preprocessor = make_transformer(X_train, 0.95, 0.95)\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "X_cal_proc = preprocessor.transform(X_cal)\n",
    "X_test_proc = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "537dfb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Types\n",
    "num_cols = [c for c in X_train_proc.columns if c.startswith(\"num__\")]\n",
    "cat_cols       = [c for c in X_train_proc.columns if c.startswith(\"cat__\")]\n",
    "rev_cols       = [c for c in X_train_proc.columns if c.startswith(\"rev__\")]\n",
    "sum_cols       = [c for c in X_train_proc.columns if c.startswith(\"sum__\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9a371",
   "metadata": {},
   "source": [
    "Models to Fit **Without** Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351f27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the models found in hyperparameter tuning\n",
    "model_2_wo_cat = LogisticRegression(penalty='l2', solver='newton-cg', C=0.1, class_weight={0: 1, 1: 250}, max_iter=1000, random_state=42) # best overall\n",
    "model_7_wo_cat = RandomForestClassifier(n_estimators=300,\n",
    "                                 class_weight={0:1.0, 1:250.0},\n",
    "                                 max_depth=5,\n",
    "                                 min_samples_split=10,\n",
    "                                 min_samples_leaf=3,\n",
    "                                 max_features='log2',\n",
    "                                 random_state=42)\n",
    "model_8_wo_cat = XGBClassifier(\n",
    "    n_estimators=300, max_depth=5, learning_rate=0.01,\n",
    "    subsample=0.6, colsample_bytree=0.6,\n",
    "    reg_alpha=0.5, reg_lambda=1.0,\n",
    "    scale_pos_weight=400.0,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42, n_jobs=-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d600d",
   "metadata": {},
   "source": [
    "Models to Fit **With** Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263e2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the models found in hyperparameter tuning\n",
    "model_4 = LogisticRegression(penalty='l2', solver='newton-cg', C=1.0, class_weight='balanced', max_iter=1000, random_state=42)\n",
    "model_5 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, class_weight={0: 1, 1: 250}, max_iter=1000, random_state=42) # best overall\n",
    "model_6 = LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, class_weight={0: 1, 1: 400}, max_iter=1000, random_state=42)\n",
    "model_7 = RandomForestClassifier(n_estimators=300,\n",
    "                                 class_weight={0:1.0, 1:250.0},\n",
    "                                 max_depth=5,\n",
    "                                 min_samples_split=10,\n",
    "                                 min_samples_leaf=3,\n",
    "                                 max_features='log2',\n",
    "                                 random_state=42)\n",
    "model_8 = XGBClassifier(\n",
    "    n_estimators=300, max_depth=5, learning_rate=0.01,\n",
    "    subsample=0.6, colsample_bytree=0.6,\n",
    "    reg_alpha=0.5, reg_lambda=1.0,\n",
    "    scale_pos_weight=400.0,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42, n_jobs=-3)\n",
    "\n",
    "model_9 = RandomForestClassifier(n_estimators=300,\n",
    "                                 class_weight='balanced',\n",
    "                                 max_depth=5,\n",
    "                                 min_samples_split=10,\n",
    "                                 min_samples_leaf=3,\n",
    "                                 max_features='log2',\n",
    "                                 random_state=42)\n",
    "\n",
    "model_10 = XGBClassifier(\n",
    "    n_estimators=300, max_depth=3, learning_rate=0.05,\n",
    "    subsample=0.6, colsample_bytree=1.0,\n",
    "    reg_alpha=0.0, reg_lambda=0.5,\n",
    "    scale_pos_weight=250.0,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42, n_jobs=-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de87c1",
   "metadata": {},
   "source": [
    "Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69ae8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop categorical columns\n",
    "X_train_wo_cat_proc = X_train_proc.drop(columns=cat_cols)\n",
    "X_val_wo_cat_proc = X_val_proc.drop(columns=cat_cols)\n",
    "X_cal_wo_cat_proc = X_cal_proc.drop(columns=cat_cols)\n",
    "X_test_wo_cat_proc = X_test_proc.drop(columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f3958a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebekaheichberg/anaconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:36:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1744329043786/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=-3, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=-3, num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=-3, num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit models\n",
    "# models without cat_cols\n",
    "model_2_wo_cat.fit(X_train_wo_cat_proc, y_train)\n",
    "model_7_wo_cat.fit(X_train_wo_cat_proc, y_train)\n",
    "model_8_wo_cat.fit(X_train_wo_cat_proc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9561a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebekaheichberg/anaconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:39:37] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1744329043786/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/rebekaheichberg/anaconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:41:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1744329043786/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# fit models\n",
    "# models with cat_cols\n",
    "model_4.fit(X_train_proc, y_train)\n",
    "model_5.fit(X_train_proc, y_train)\n",
    "model_6.fit(X_train_proc, y_train)\n",
    "model_7.fit(X_train_proc, y_train)\n",
    "model_8.fit(X_train_proc, y_train)\n",
    "model_9.fit(X_train_proc, y_train)\n",
    "model_10.fit(X_train_proc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6095a6",
   "metadata": {},
   "source": [
    "Calibrate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap already-fitted model\n",
    "cal_model_2_wo_cat = CalibratedClassifierCV(estimator=model_2_wo_cat, method='sigmoid', cv='prefit')\n",
    "cal_model_7_wo_cat = CalibratedClassifierCV(estimator=model_7_wo_cat, method='sigmoid', cv='prefit')\n",
    "cal_model_8_wo_cat = CalibratedClassifierCV(estimator=model_8_wo_cat, method='sigmoid', cv='prefit')\n",
    "\n",
    "cal_model_4 = CalibratedClassifierCV(estimator=model_4, method='sigmoid', cv='prefit')\n",
    "cal_model_5 = CalibratedClassifierCV(estimator=model_5, method='sigmoid', cv='prefit')\n",
    "cal_model_6 = CalibratedClassifierCV(estimator=model_6, method='sigmoid', cv='prefit')\n",
    "cal_model_7 = CalibratedClassifierCV(estimator=model_7, method='sigmoid', cv='prefit')\n",
    "cal_model_8 = CalibratedClassifierCV(estimator=model_8, method='sigmoid', cv='prefit' )\n",
    "cal_model_9 = CalibratedClassifierCV(estimator=model_9, method='sigmoid', cv='prefit' )\n",
    "cal_model_10 = CalibratedClassifierCV(estimator=model_10, method='sigmoid', cv='prefit' )\n",
    "\n",
    "\n",
    "# fit calibration model on calibration set\n",
    "cal_model_4.fit(X_cal_proc, y_cal)\n",
    "cal_model_5.fit(X_cal_proc, y_cal)\n",
    "cal_model_6.fit(X_cal_proc, y_cal)\n",
    "cal_model_7.fit(X_cal_proc, y_cal)\n",
    "cal_model_8.fit(X_cal_proc, y_cal)\n",
    "cal_model_9.fit(X_cal_proc, y_cal)\n",
    "cal_model_10.fit(X_cal_proc, y_cal)\n",
    "cal_model_2_wo_cat.fit(X_cal_wo_cat_proc, y_cal)\n",
    "cal_model_7_wo_cat.fit(X_cal_wo_cat_proc, y_cal)\n",
    "cal_model_8_wo_cat.fit(X_cal_wo_cat_proc, y_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf5031",
   "metadata": {},
   "source": [
    "Manual 'Voting' Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7d9c1",
   "metadata": {},
   "source": [
    "**With** Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities on calibrated model\n",
    "proba_lr = cal_model_5.predict_proba(X_test_proc)\n",
    "proba_rf = cal_model_7.predict_proba(X_test_proc)\n",
    "proba_xgb = cal_model_8.predict_proba(X_test_proc)\n",
    "\n",
    "# take average to get 'voting classifier'\n",
    "avg_proba = (proba_lr + proba_rf + proba_xgb) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b6fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use predetermined threshold coming from imbalance weights\n",
    "threshold = 1/146\n",
    "\n",
    "# probability for class 1\n",
    "proba_class1 = avg_proba[:, 1]\n",
    "\n",
    "# apply the threshold\n",
    "preds = (proba_class1 >= threshold).astype(int)\n",
    "print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, avg_proba[:,1], n_bins=10, strategy='uniform')\n",
    "\n",
    "# Optional: Compute bin centers and counts for potential histogram overlay\n",
    "# bin_edges = np.linspace(0, 1, 11)\n",
    "# bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "# bin_counts, _ = np.histogram(proba_class1, bins=bin_edges)\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibrated Model', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "plt.xlabel('Mean Predicted Probability (per bin)')\n",
    "plt.ylabel('True Fraction of Positives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold\n",
    "threshold = 1 / 146 \n",
    "\n",
    "# compute calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, proba_class1, n_bins=10, strategy='uniform')\n",
    "\n",
    "# Optional: Compute bin centers and counts for potential histogram overlay\n",
    "# bin_edges = np.linspace(0, 1, 11)\n",
    "# bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "# bin_counts, _ = np.histogram(proba_class1, bins=bin_edges)\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibrated Model', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "\n",
    "# Vertical threshold line\n",
    "plt.axvline(x=threshold, color='red', linestyle='--')\n",
    "plt.text(threshold + 0.005, 0.1, f'Threshold = 1/146 ≈ {threshold:.3f}', color='red', rotation=90, va='bottom')\n",
    "\n",
    "# # Optional: Histogram overlay (commented)\n",
    "# ax = plt.gca()\n",
    "# ax2 = ax.twinx()\n",
    "# ax2.bar(bin_centers, bin_counts, width=0.08, color='lightgray', alpha=0.3, label='Bin Support')\n",
    "# ax2.set_ylabel('Sample Count per Bin')\n",
    "\n",
    "# Zoom in for better visibility of low-threshold region\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0, 1.05)\n",
    "\n",
    "# Labels and styling\n",
    "plt.xlabel('Mean Predicted Probability (per bin)')\n",
    "plt.ylabel('True Fraction of Positives')\n",
    "plt.title('Reliability Curve (Threshold = 1/146 ≈ 0.00685)')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold\n",
    "threshold = 1 / 146  # ≈ 0.00685\n",
    "\n",
    "# Calibration curve with high-resolution bins\n",
    "n_bins = 100\n",
    "prob_true, prob_pred = calibration_curve(y_test, proba_class1, n_bins=n_bins, strategy='uniform')\n",
    "\n",
    "# Create subplot layout\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5), gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "### Plot 1: Reliability Curve ###\n",
    "axs[0].plot(prob_pred, prob_true, marker='o', label='Calibrated Model', linewidth=2)\n",
    "axs[0].plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "\n",
    "# Threshold line and annotation\n",
    "axs[0].axvline(x=threshold, color='red', linestyle='--')\n",
    "axs[0].text(threshold + 0.002, 0.1, f'Threshold = 1/146 ≈ {threshold:.3f}', color='red', rotation=90, va='bottom')\n",
    "\n",
    "axs[0].set_xlim(0, 0.05)  # Zoom in for threshold visibility\n",
    "axs[0].set_ylim(0, 1.05)\n",
    "axs[0].set_xlabel('Mean Predicted Probability (per bin)')\n",
    "axs[0].set_ylabel('True Fraction of Positives')\n",
    "axs[0].set_title('Reliability Curve (High Resolution)')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "### Plot 2: Histogram of Predicted Probabilities ###\n",
    "axs[1].hist(proba_class1, bins=100, color='steelblue', edgecolor='black')\n",
    "axs[1].axvline(x=threshold, color='red', linestyle='--', label=f'Threshold ≈ {threshold:.3f}')\n",
    "axs[1].set_xlim(0, 0.05)\n",
    "axs[1].set_xlabel('Predicted Probability')\n",
    "axs[1].set_ylabel('Sample Count')\n",
    "axs[1].set_title('Distribution of Predicted Probabilities')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold\n",
    "threshold = 1 / 146  # ≈ 0.00685\n",
    "\n",
    "# Calibration curve with high-resolution bins\n",
    "n_bins = 100\n",
    "prob_true, prob_pred = calibration_curve(y_test, proba_class1, n_bins=n_bins, strategy='uniform')\n",
    "\n",
    "# Create subplot layout\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5), gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "### Plot 1: Reliability Curve (Log scale) ###\n",
    "axs[0].plot(prob_pred, prob_true, marker='o', label='Calibrated Model', linewidth=2)\n",
    "axs[0].plot([1e-5, 1], [1e-5, 1], linestyle='--', color='gray', label='Perfect Calibration')  # Start from low\n",
    "\n",
    "# Threshold line and annotation\n",
    "axs[0].axvline(x=threshold, color='red', linestyle='--')\n",
    "axs[0].text(threshold * 1.5, 0.1, f'Thresh = 1/146 ≈ {threshold:.3f}', color='red', rotation=90, va='bottom')\n",
    "\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_xlim(1e-4, 1)  # Log scale bounds\n",
    "axs[0].set_ylim(0, 1.05)\n",
    "axs[0].set_xlabel('Mean Predicted Probability (log scale)')\n",
    "axs[0].set_ylabel('True Fraction of Positives')\n",
    "axs[0].set_title('Reliability Curve (Log Scale)')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "\n",
    "### Plot 2: Histogram of Predicted Probabilities (Log scale) ###\n",
    "axs[1].hist(proba_class1, bins=np.logspace(-4, 0, 100), color='steelblue', edgecolor='black')\n",
    "axs[1].axvline(x=threshold, color='red', linestyle='--', label=f'Thresh ≈ {threshold:.3f}')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_xlim(1e-4, 1)\n",
    "axs[1].set_xlabel('Predicted Probability (log scale)')\n",
    "axs[1].set_ylabel('Sample Count')\n",
    "axs[1].set_title('Distribution of Predicted Probabilities')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c77859",
   "metadata": {},
   "source": [
    "Balanced Weight 'Voting Classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b96d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities on calibrated model\n",
    "proba_lr_bal = cal_model_4.predict_proba(X_test_proc)\n",
    "proba_rf_bal = cal_model_9.predict_proba(X_test_proc)\n",
    "proba_xgb_bal = cal_model_10.predict_proba(X_test_proc)\n",
    "\n",
    "# take average to make 'voting classifier'\n",
    "avg_proba_bal = (proba_lr_bal + proba_rf_bal + proba_xgb_bal) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, avg_proba[:,1], n_bins=10, strategy='uniform')\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibrated Model', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "plt.xlabel('Mean Predicted Probability (per bin)')\n",
    "plt.ylabel('True Fraction of Positives')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afcd860",
   "metadata": {},
   "source": [
    "**Without** Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities on calibrated model\n",
    "proba_lr_wo_cat = cal_model_2_wo_cat.predict_proba(X_test_wo_cat_proc)\n",
    "proba_rf_wo_cat = cal_model_7_wo_cat.predict_proba(X_test_wo_cat_proc)\n",
    "proba_xgb_wo_cat = cal_model_8_wo_cat.predict_proba(X_test_wo_cat_proc)\n",
    "\n",
    "# take average to make 'voting classifier'\n",
    "avg_proba_wo_cat = (proba_lr_wo_cat + proba_rf_wo_cat + proba_xgb_wo_cat) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a threshold\n",
    "threshold = 1/146\n",
    "\n",
    "# probability for class 1\n",
    "proba_class1_wo_cat = avg_proba_wo_cat[:, 1]\n",
    "\n",
    "# apply the threshold\n",
    "preds_wo_cat = (proba_class1_wo_cat >= threshold).astype(int)\n",
    "print(classification_report(y_test, preds_wo_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc242115",
   "metadata": {},
   "source": [
    "Anamoly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_series = pd.Series(proba_class1, name=\"P(class=1)\")\n",
    "\n",
    "# calculate the average predicted probability\n",
    "mean_prob = proba_series.mean()\n",
    "\n",
    "# Find anomalies: probabilities > average\n",
    "anomalies = proba_series[proba_series > 10*mean_prob]\n",
    "\n",
    "# Optionally inspect\n",
    "print(f\"Mean predicted P(class=1): {10*mean_prob:.4f}\")\n",
    "print(f\"Number of anomalies (above mean): {len(anomalies)}\")\n",
    "\n",
    "# To view the anomalous rows with their indices and probabilities\n",
    "# print(anomalies.sort_values(ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, proba_class1)\n",
    "\n",
    "# threshold for 90% precision\n",
    "target_precision = 0.90\n",
    "idx = next(i for i, p in enumerate(precision) if p >= target_precision)\n",
    "best_thresh = thresholds[idx]\n",
    "\n",
    "anomalies = proba_series[proba_series > best_thresh]\n",
    "print(f\"Threshold for ≥90% precision: {best_thresh:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proba_class1 = model.predict_proba(X_test)[:, 1]\n",
    "proba_series = pd.Series(proba_class1, name=\"P(class=1)\")\n",
    "mean_prob = proba_series.mean()\n",
    "anomalies = proba_series[proba_series > 10*mean_prob]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(proba_series, bins=50, kde=True, color='steelblue', edgecolor='black', label='All Probabilities')\n",
    "plt.axvline(mean_prob, color='orange', linestyle='--', linewidth=2, label=f'Mean = {mean_prob:.3f}')\n",
    "plt.axvspan(mean_prob, proba_series.max(), color='red', alpha=0.2, label='Anomalies > Mean')\n",
    "\n",
    "# Styling\n",
    "plt.title('Distribution of P(class=1) with Anomalies')\n",
    "plt.xlabel('Predicted Probability of Class 1')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'proba_class1': proba_class1\n",
    "})\n",
    "\n",
    "# Filter to only true class = 0\n",
    "df_negatives = df[df['y_true'] == 0]\n",
    "\n",
    "# set anomaly threshold\n",
    "threshold = df_negatives['proba_class1'].quantile(0.90)\n",
    "\n",
    "# flag anomalies\n",
    "anomalies = df_negatives[df_negatives['proba_class1'] > threshold]\n",
    "\n",
    "print(f\"Anomaly threshold (90th percentile among true class 0): {threshold:.4f}\")\n",
    "print(f\"Number of flagged anomalies: {len(anomalies)}\")\n",
    "\n",
    "# plot \n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_negatives['proba_class1'], bins=50, kde=True, color='steelblue', edgecolor='black', label='P(class=1) | y_true = 0')\n",
    "plt.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'90th percentile = {threshold:.3f}')\n",
    "plt.axvspan(threshold, df_negatives['proba_class1'].max(), color='red', alpha=0.2, label='Anomalies')\n",
    "\n",
    "plt.title('Anomaly Detection: High P(class=1) among True Class 0')\n",
    "plt.xlabel('Predicted Probability of Class 1')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb38578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assume these exist:\n",
    "# proba_class1: 1D array or Series with predicted P(class=1)\n",
    "# y_true: 1D array or Series with true labels (0 or 1)\n",
    "\n",
    "# Convert to Series for convenience (if not already)\n",
    "proba_series = pd.Series(proba_class1, name=\"P(class=1)\")\n",
    "y_true_series = pd.Series(y_test, name=\"true_label\")\n",
    "\n",
    "# Filter probabilities only where y_true == 0\n",
    "proba_filtered = proba_series[y_true_series.values == 0]\n",
    "\n",
    "# Calculate the average predicted probability for the filtered subset\n",
    "mean_prob = proba_filtered.mean()\n",
    "\n",
    "mean_prob_ten_times = 10*mean_prob\n",
    "\n",
    "# Find anomalies: probabilities > average in the filtered subset\n",
    "anomalies = proba_filtered[proba_filtered > mean_prob_ten_times]\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean predicted P(class=1) for y_true=0: {mean_prob:.4f}\")\n",
    "print(f\"Mean predicted P(class=1) for y_true=0: {mean_prob_ten_times:.4f}\")\n",
    "print(f\"Number of anomalies (above mean) with y_true=0: {len(anomalies)}\")\n",
    "\n",
    "# View the anomalous probabilities sorted descending (with original indices)\n",
    "#print(anomalies.sort_values(ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ccdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assume these exist:\n",
    "# proba_class1: 1D array or Series with predicted P(class=1)\n",
    "# y_test: 1D array or Series with true labels (0 or 1)\n",
    "\n",
    "# Convert to Series with aligned index\n",
    "proba_series = pd.Series(proba_class1).reset_index(drop=True)\n",
    "y_true_series = pd.Series(y_test).reset_index(drop=True)\n",
    "\n",
    "# Filter only true negatives (y_true == 0)\n",
    "proba_filtered = proba_series[y_true_series == 0]\n",
    "\n",
    "# Compute mean probability for y_true == 0\n",
    "mean_prob = proba_filtered.mean()\n",
    "mean_prob_ten_times = 10 * mean_prob\n",
    "\n",
    "# Find anomalies (flagged when predicted prob > threshold)\n",
    "anomalies = proba_filtered[proba_filtered > mean_prob_ten_times]\n",
    "\n",
    "# Compute percent of y_true==0 that were flagged\n",
    "percent_flagged = len(anomalies) / len(proba_filtered) * 100\n",
    "\n",
    "# Print summary\n",
    "print(f\"Mean predicted P(class=1) for y_true=0: {mean_prob:.4f}\")\n",
    "print(f\"10x mean threshold: {mean_prob_ten_times:.4f}\")\n",
    "print(f\"Anomalies (P > 10x mean) with y_true=0: {len(anomalies)}\")\n",
    "print(f\"Percent of y_true=0 flagged as anomalies: {percent_flagged:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
