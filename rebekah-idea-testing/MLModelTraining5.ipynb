{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb4fba-1866-4d33-85e6-bb115ee08aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a3c23-0b19-45bf-bd14-add6510b1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"../train_final_v3.parquet\")\n",
    "val_df = pd.read_parquet(\"../validationA_v3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4e1d6-21cb-495f-9544-ab6116254283",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e9204d-9314-464e-82d7-b9f70b32bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[:,:25].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a58c43-dc2c-4724-91cc-7d5e8937c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['match'], axis=1)\n",
    "X_val = val_df.drop(columns=['match'], axis=1)\n",
    "y_train = train_df['match']\n",
    "y_val = val_df['match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923d239-a708-4ed1-b0af-bea35d005d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = X_train\n",
    "X_val_raw = X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e1191-1949-4e52-8a4d-4b3d2fb16e95",
   "metadata": {},
   "source": [
    "## Columns Type Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377f47d-7ffd-4b26-bae5-e2a3f0876295",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (X_train, X_val):\n",
    "    df['review_span'] = (df['max_date'] - df['min_date']).dt.days\n",
    "    df.drop(['min_date', 'max_date'], axis=1, inplace=True)\n",
    "\n",
    "for df in (X_train, X_val):\n",
    "    df['missing_price'] = df['missing_price'].astype(int)\n",
    "\n",
    "for df in (X_train, X_val):\n",
    "    df['product_lifespan_days'] = df['product_lifespan'].dt.days\n",
    "    df.drop('product_lifespan', axis=1, inplace=True)\n",
    "\n",
    "print(f\"The shape of X_train: {X_train.shape}, X_val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf90fd-2a0d-4556-b231-d366ef47f6c3",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c170b-9bd6-4179-9949-8e26f2e6ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "corr = X_train.drop(columns=['category']).corr()\n",
    "mask = np.triu(np.ones(corr.shape, dtype=bool), k=1)\n",
    "high_corr_pairs = (corr.where(mask).stack().reset_index(name='correlation')\n",
    "                   .query('abs(correlation) > 0.9')\n",
    "                   .rename(columns={'level_0':'Feature1','level_1':'Feature2'}))\n",
    "print(high_corr_pairs)\n",
    "top = (high_corr_pairs.assign(AbsCorr=lambda df: df['correlation'].abs())\n",
    "       .nlargest(50,'AbsCorr')\n",
    "       .pivot(index='Feature1', columns='Feature2', values='AbsCorr'))\n",
    "plt.figure(figsize=(6,5))\n",
    "ax = sns.heatmap(top, annot=True, cmap='coolwarm', fmt=\".2f\", cbar_kws={'label':'Abs Pearson œÅ'})\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, va='center')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c2b54-6e43-41ff-b6da-68c412758251",
   "metadata": {},
   "source": [
    "We will drop the columns `percent_positive`, `percent_negative`,  `review_span ` and `unique_reviewer_count` as they exhibit high correlation with other features, which may introduce multicollinearity into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1472b3e-e234-4e74-96c4-15e7bf805e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (X_train, X_val):\n",
    "    df.drop(['percent_positive', 'percent_negative', 'unique_reviewer_count', 'review_span'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b734343-f74b-4f2c-9a02-4ee6a7eb5a2b",
   "metadata": {},
   "source": [
    "## Preprocessing, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0183f-c3f9-4257-9475-eb42ffad4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "def make_transformer(df,r, s, drop_first=True):\n",
    "    rev_cols  = [c for c in df if c.startswith(\"embedding_\")]\n",
    "    summ_cols = [c for c in df if c.startswith(\"embed_\")]\n",
    "    numeric_cols  = [c for c in df if c not in rev_cols+summ_cols+[\"category\"]]\n",
    "\n",
    "    rev_pipe  = (\"drop\" if r == 0 else Pipeline([(\"scale\",StandardScaler()), (\"pca\",PCA(n_components=r,random_state=42))]))\n",
    "    sum_pipe  = (\"drop\" if s == 0 else Pipeline([(\"scale\",StandardScaler()), (\"pca\",PCA(n_components=s,random_state=42))]))\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        [('num', StandardScaler(), numeric_cols),\n",
    "         ('cat', OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\" if drop_first else None, sparse_output=False), [\"category\"]),\n",
    "         ('rev', rev_pipe,  rev_cols),\n",
    "         ('sum', sum_pipe,  summ_cols)\n",
    "        ]).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9fecf-2ad4-4179-a8ff-3e578365f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_transformer(X_train, 0.95, 0.95)\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23a287-e2e3-4ba7-a416-0ad7bff8a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Types\n",
    "num_cols = [c for c in X_train_proc.columns if c.startswith(\"num__\")]\n",
    "cat_cols       = [c for c in X_train_proc.columns if c.startswith(\"cat__\")]\n",
    "rev_cols       = [c for c in X_train_proc.columns if c.startswith(\"rev__\")]\n",
    "sum_cols       = [c for c in X_train_proc.columns if c.startswith(\"sum__\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c992ad-f410-4a91-ba0d-cf00de50acf5",
   "metadata": {},
   "source": [
    "## Multicollinearity: Variance Inflation Factor (VIF) On Non-Embedding Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7baaafe-eb2b-4b2c-933a-fb6e3cd94a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def compute_vif(X_train_proc, numeric_cols, categorical_cols, thresh=10):\n",
    "    nonembed_cols = numeric_cols + categorical_cols\n",
    "    X_vif = X_train_proc[nonembed_cols].copy()\n",
    "\n",
    "    # drop constant / near-constant columns\n",
    "    const_cols = X_vif.columns[X_vif.std() < 1e-12]\n",
    "    if len(const_cols):\n",
    "        X_vif.drop(columns=const_cols, inplace=True)\n",
    "\n",
    "    # VIF calculation \n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X_vif.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "    # Print features with VIF > 10\n",
    "    high_vif = vif_data[vif_data[\"VIF\"] > thresh].sort_values(\"VIF\", ascending=False)\n",
    "    if not high_vif.empty:\n",
    "        print(f\"Features with VIF > {thresh}:\")\n",
    "        print(high_vif.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"No features with VIF > {thresh}\")\n",
    "\n",
    "    return vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b4b0a-a567-44d6-b92b-3d5ee46e861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = compute_vif(X_train_proc, num_cols, cat_cols, thresh=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c80e18-c0bb-4f7c-95cf-ac8a71de0320",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b93d1-26a7-4bb2-a5ca-f3a4b45d401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, penalty='l1', solver='liblinear', class_weight=\"balanced\", random_state=42)\n",
    "log_reg.fit(X_train_proc, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_val_proc)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946c6a0-0d07-480e-8163-633edfecc918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent   \n",
    "sys.path.insert(0, str(project_root / \"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8232a523-b552-44c2-b68d-4fbac71f3a3d",
   "metadata": {},
   "source": [
    "## Custom KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9739069-f4cc-4e4b-bbd3-74512db267c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../Data/')\n",
    "from get_cv_split import PredefinedKFold\n",
    "split_data=pd.read_parquet(\"../Data/CV_val_split.parquet\")\n",
    "assert((split_data.index==X_train.index).all()) # Sanity check to verify indices of X_train match up with indices of split_data\n",
    "kfold=PredefinedKFold(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c9a1d-cae1-4428-9239-ef0f6f6052ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "recall_macro_scorer = make_scorer(recall_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(log_reg, X_train_proc, y_train, cv=kfold, scoring=recall_macro_scorer)\n",
    "\n",
    "print(\"Macro Recall (per fold):\", scores)\n",
    "print(\"Mean Macro Recall:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d0d17-f3c8-43a8-a578-42bd562c36ea",
   "metadata": {},
   "source": [
    "### GridSearchCV on r and s (The PCA dimension of Review and Summary Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ac48d-7ea2-4240-a6ab-561642cfb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, average_precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"fe\", make_transformer(X_train, r=50, s=10)),  # Dummy values, will be overridden by grid search\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "grid_vals = [10, 20, 50, 100]\n",
    "param_grid = {\n",
    "    \"fe__rev__pca__n_components\": grid_vals,  # r\n",
    "    \"fe__sum__pca__n_components\": grid_vals   # s\n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    \"pr_auc\": make_scorer(average_precision_score, needs_proba=True),\n",
    "    \"recall_macro\": make_scorer(recall_score, average=\"macro\"),\n",
    "    \"f1_macro\": make_scorer(f1_score, average=\"macro\"),\n",
    "}\n",
    "\n",
    "# Run GridSearchCV\n",
    "gcv = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorers,\n",
    "    refit=\"recall_macro\",  \n",
    "    cv=kfold,              \n",
    "    n_jobs=20,\n",
    "    return_train_score=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "gcv.fit(X_train, y_train)  \n",
    "\n",
    "# Extract results\n",
    "results = (\n",
    "    pd.DataFrame(gcv.cv_results_)\n",
    "    .loc[:, [\n",
    "        \"param_fe__rev__pca__n_components\",\n",
    "        \"param_fe__sum__pca__n_components\",\n",
    "        \"mean_test_pr_auc\", \"std_test_pr_auc\",\n",
    "        \"mean_test_recall_macro\", \"std_test_recall_macro\",\n",
    "        \"mean_test_f1_macro\", \"std_test_f1_macro\"\n",
    "    ]]\n",
    "    .rename(columns={\n",
    "        \"param_fe__rev__pca__n_components\": \"r\",\n",
    "        \"param_fe__sum__pca__n_components\": \"s\",\n",
    "        \"mean_test_pr_auc\": \"pr_auc_mean\",\n",
    "        \"std_test_pr_auc\": \"pr_auc_std\",\n",
    "        \"mean_test_recall_macro\": \"recall_macro_mean\",\n",
    "        \"std_test_recall_macro\": \"recall_macro_std\",\n",
    "        \"mean_test_f1_macro\": \"f1_macro_mean\",\n",
    "        \"std_test_f1_macro\": \"f1_macro_std\"\n",
    "    })\n",
    "    .sort_values(\"recall_macro_mean\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(results.head())\n",
    "\n",
    "# Best model ready to use\n",
    "best_lr = gcv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db3bf86-39b7-40a4-8f50-a31358db2643",
   "metadata": {},
   "source": [
    "From the results, we observe that there is not much difference between the different values of r and s. So, we will choose r = 50 and s = 10 since with these values model performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81051264-d3fe-4bfd-9d50-c7250e3d3dbd",
   "metadata": {},
   "source": [
    "## Feature Selection With Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21db95-85b2-41b0-8617-efd0baf64a01",
   "metadata": {},
   "source": [
    "#### Preprocessing with r=50, s=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ffe85-8865-409b-97e4-32a8510306e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_transformer(X_train, r=50, s=10)\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "# update columns names\n",
    "num_cols = [c for c in X_train_proc.columns if c.startswith(\"num__\")]\n",
    "cat_cols       = [c for c in X_train_proc.columns if c.startswith(\"cat__\")]\n",
    "rev_cols       = [c for c in X_train_proc.columns if c.startswith(\"rev__\")]\n",
    "sum_cols       = [c for c in X_train_proc.columns if c.startswith(\"sum__\")]\n",
    "\n",
    "print(f\"After preprocessing X_train_proc:\", X_train_proc.shape)\n",
    "print(f\"After preprocessing X_val_proc:\", X_val_proc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94074720-ef9b-44dd-a6e5-b66beed9cc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9eddb7-caee-47c6-b0e8-60ab4f976b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "l1_model = LogisticRegression(penalty='l1', solver='saga', class_weight='balanced', C=0.1, random_state=42)\n",
    "l1_model.fit(X_train_proc, y_train)\n",
    "\n",
    "selector = SelectFromModel(l1_model, prefit=True)\n",
    "X_train_sel = selector.transform(X_train_proc)\n",
    "selected_feats = X_train_proc.columns[selector.get_support()]\n",
    "\n",
    "print(f\"Selected {len(selected_feats)} features:\")\n",
    "print(selected_feats.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef0add-92ae-43d4-bb23-8e73c1ba8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get coefficients and feature names\n",
    "coefs = l1_model.coef_[0]\n",
    "feature_names = X_train_proc.columns\n",
    "\n",
    "# Create a DataFrame\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefs,\n",
    "    'abs_coefficient': np.abs(coefs)\n",
    "})\n",
    "\n",
    "# Get top 20 features by absolute coefficient\n",
    "top20 = coef_df.sort_values(by='abs_coefficient', ascending=False).tail(20)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top20['feature'][::-1], top20['coefficient'][::-1])\n",
    "plt.title('Top 20 L1 Logistic Regression Coefficients')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d420bc3-2d36-423e-aaf1-cd42ab7f5a8d",
   "metadata": {},
   "source": [
    "It looks like category features are very important. We will drop category features and regenerate the featue importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88989d1-8028-4a12-8c2d-132dae840541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop category columns\n",
    "X_train_proc_wo_cat = X_train_proc.drop(columns=cat_cols, axis=1)\n",
    "X_val_proc_wo_cat = X_val_proc.drop(columns=cat_cols, axis=1)\n",
    "\n",
    "print(f\"After dropping categorical columns from train dataframe:\", X_train_proc_wo_cat.shape)\n",
    "print(f\"After dropping categorical columns from val dataframe:\", X_val_proc_wo_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d2fef-e29c-44b2-8052-9c0ad933ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_model.fit(X_train_proc_wo_cat, y_train)\n",
    "\n",
    "selector = SelectFromModel(l1_model, prefit=True)\n",
    "X_train_sel = selector.transform(X_train_proc_wo_cat)\n",
    "selected_feats = X_train_proc_wo_cat.columns[selector.get_support()]\n",
    "\n",
    "print(f\"Selected {len(selected_feats)} features:\")\n",
    "print(selected_feats.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6792e-78fd-4727-a056-c3160e68c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get coefficients and feature names\n",
    "coefs = l1_model.coef_[0]\n",
    "feature_names = X_val_proc_wo_cat.columns\n",
    "\n",
    "# Create a DataFrame\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefs,\n",
    "    'abs_coefficient': np.abs(coefs)\n",
    "})\n",
    "\n",
    "# Get top 20 features by absolute coefficient\n",
    "top20 = coef_df.sort_values(by='abs_coefficient', ascending=False).head(20)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top20['feature'][::-1], top20['coefficient'][::-1])\n",
    "plt.title('Top 20 L1 Logistic Regression Coefficients')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cfd01-8ce8-402b-b93c-48cb1d43d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "recall_macro_scorer = make_scorer(recall_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(log_reg, X_train_proc_wo_cat, y_train, cv=kfold, scoring=recall_macro_scorer)\n",
    "\n",
    "print(\"Macro Recall (per fold):\", scores)\n",
    "print(\"Mean Macro Recall:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db082c54-78cb-4cef-90a1-cad32cd050e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000, penalty='l1', solver='liblinear', class_weight=\"balanced\", random_state=42)\n",
    "log_reg.fit(X_train_proc_wo_cat, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_val_proc_wo_cat)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d40bd29-b3f2-40bd-a018-f6842194620d",
   "metadata": {},
   "source": [
    "Dropping category improves the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4699869-0880-41d7-9c25-cb3c73c90585",
   "metadata": {},
   "source": [
    "Rebekah Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22741f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train_cat_chi = X_train_proc[cat_cols]\n",
    "X_val_cat_chi = X_val_proc[cat_cols]\n",
    "\n",
    "chi_selector = SelectKBest(score_func=chi2, k='all')\n",
    "chi_selector.fit(X_train_cat_chi, y_train)\n",
    "\n",
    "chi_scores = pd.Series(chi_selector.scores_, index=X_train_cat_chi.columns).sort_values(ascending=False)\n",
    "\n",
    "# Keep top k categorical features\n",
    "top_k_cat = chi_scores.index.tolist()\n",
    "X_cat_reduced = X_train_cat_chi[top_k_cat]\n",
    "\n",
    "chi_scores.sort_values(ascending=True).plot(kind='barh', figsize=(8, 6), title='Chi-Squared Scores by Category')\n",
    "plt.xlabel(\"Chi-squared Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e527b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_scores_features = chi_scores[chi_scores > 10].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_scores_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06459601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mi = mutual_info_classif(X_train_proc, y_train, discrete_features=[False]*76 + [True]*len(cat_cols))\n",
    "\n",
    "mi_scores = pd.Series(mi, index=X_train_proc.columns).sort_values(ascending=False)\n",
    "\n",
    "# Select top K features overall\n",
    "top_k_mi = mi_scores.index.tolist()\n",
    "X_selected = X_train_proc[top_k_mi]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a39504",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 50\n",
    "mi_top = mi_scores.sort_values(ascending=False).tail(top_n)\n",
    "\n",
    "plt.figure(figsize=(10, 12))  # wider and taller\n",
    "mi_top.sort_values().plot(kind='barh', color='skyblue')  # horizontal bar chart\n",
    "plt.xlabel(\"Mutual Information Score\")\n",
    "plt.ylabel('Feature')\n",
    "plt.title(\"Bottom 50 Mutual Information Scores\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3414ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_score_features = mi_scores[mi_scores > 0.013].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = list(set(chi_scores_features).union(set(mi_score_features)))\n",
    "X_fs_train_final = X_train_proc[final_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfecd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs_val_final = X_val_proc[final_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c481831",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wo_cat = X_train_proc.drop(columns=cat_cols)\n",
    "X_val_wo_cat = X_val_proc.drop(columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd63172",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_wo_cat = LogisticRegression(penalty='l1', solver='saga', class_weight={0:1, 1:600}, random_state=42, C=0.10)\n",
    "log_reg_wo_cat.fit(X_train_proc_wo_cat, y_train)\n",
    "\n",
    "y_pred = log_reg_wo_cat.predict(X_val_proc_wo_cat)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ff73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_w_cat = LogisticRegression(penalty='l1', solver='saga', class_weight={0:1, 1:600}, random_state=42, C=10)\n",
    "log_reg_w_cat.fit(X_train_proc, y_train)\n",
    "\n",
    "y_pred = log_reg_w_cat.predict(X_val_proc)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_wo_cat = RandomForestClassifier(n_estimators=400,\n",
    "                                   min_samples_split=5,\n",
    "                                   min_samples_leaf=3,\n",
    "                                   max_features='log2',\n",
    "                                   max_depth=7,\n",
    "                                   class_weight={0: 1.0, 1: 600.0})\n",
    "\n",
    "rf_wo_cat.fit(X_train_proc_wo_cat, y_train)\n",
    "\n",
    "y_pred = rf_wo_cat.predict(X_val_proc_wo_cat)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeeaa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_w_cat = RandomForestClassifier(n_estimators=300,\n",
    "                                   min_samples_split=10,\n",
    "                                   min_samples_leaf=3,\n",
    "                                   max_features='log2',\n",
    "                                   max_depth=7,\n",
    "                                   class_weight={0: 1.0, 1: 600.0})\n",
    "\n",
    "rf_w_cat.fit(X_train_proc, y_train)\n",
    "\n",
    "y_pred = rf_w_cat.predict(X_val_proc)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_wo_cat = XGBClassifier(\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.05,\n",
    "    subsample = 0.8,\n",
    "    colsample_bytree = 1,\n",
    "    reg_alpha = 1,\n",
    "    reg_lambda = 1,\n",
    "    scale_pos_weight = 600\n",
    ")\n",
    "\n",
    "xgb_wo_cat.fit(X_train_proc_wo_cat, y_train)\n",
    "\n",
    "y_pred = xgb_wo_cat.predict(X_val_proc_wo_cat)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3742086",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_w_cat = XGBClassifier(\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.05,\n",
    "    subsample = 0.6,\n",
    "    colsample_bytree = 0.8,\n",
    "    reg_alpha = 0,\n",
    "    reg_lambda = 1,\n",
    "    scale_pos_weight = 600\n",
    ")\n",
    "\n",
    "xgb_w_cat.fit(X_train_proc, y_train)\n",
    "\n",
    "y_pred = xgb_w_cat.predict(X_val_proc)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade38efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train_cat_chi = X_train_proc[cat_cols]\n",
    "X_val_cat_chi = X_val_proc[cat_cols]\n",
    "\n",
    "chi_selector = SelectKBest(score_func=chi2, k='all')\n",
    "chi_selector.fit(X_train_cat_chi, y_train)\n",
    "\n",
    "chi_scores = pd.Series(chi_selector.scores_, index=X_train_cat_chi.columns).sort_values(ascending=True)\n",
    "\n",
    "# Keep top k categorical features\n",
    "top_k_cat = chi_scores.index.tolist()\n",
    "X_cat_reduced = X_train_cat_chi[top_k_cat]\n",
    "\n",
    "chi_scores.sort_values(ascending=True).plot(kind='barh', figsize=(8, 6), title='Chi-Squared Scores by Category')\n",
    "plt.xlabel(\"Chi-squared Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d045d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_chi_features = chi_scores[chi_scores < 10].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fef212",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_scores_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_cat = list(X_train_proc_wo_cat.columns)\n",
    "high_chi_cat = wo_cat + chi_scores_features\n",
    "X_train_high_chi = X_train_proc[high_chi_cat]\n",
    "X_train_high_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4249dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_cat = list(X_train_proc_wo_cat.columns)\n",
    "low_chi_cat = wo_cat + low_chi_features\n",
    "X_train_low_chi = X_train_proc[low_chi_cat]\n",
    "X_train_low_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132118d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "xgb_low_chi = XGBClassifier(\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.05,\n",
    "    subsample = 0.8,\n",
    "    colsample_bytree = 1,\n",
    "    reg_alpha = 1,\n",
    "    reg_lambda = 1,\n",
    "    scale_pos_weight = 600\n",
    ")\n",
    "\n",
    "xgb_low_chi.fit(X_train_low_chi, y_train)\n",
    "\n",
    "y_pred = xgb_low_chi.predict(X_val_proc[low_chi_cat])\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "\n",
    "print(f'PR AUC:{average_precision_score(y_val,y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_high_chi = XGBClassifier(\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.05,\n",
    "    subsample = 0.8,\n",
    "    colsample_bytree = 1,\n",
    "    reg_alpha = 1,\n",
    "    reg_lambda = 1,\n",
    "    scale_pos_weight = 600\n",
    ")\n",
    "\n",
    "xgb_high_chi.fit(X_train_high_chi, y_train)\n",
    "\n",
    "y_pred = xgb_high_chi.predict(X_val_proc[high_chi_cat])\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "\n",
    "print(f'PR AUC:{average_precision_score(y_val,y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_wo_cat = LogisticRegression(penalty='l1', solver='saga', class_weight={0:1, 1:600}, random_state=42, C=0.10)\n",
    "log_reg_wo_cat.fit(X_train_high_chi, y_train)\n",
    "\n",
    "y_pred = log_reg_wo_cat.predict(X_val_proc[high_chi_cat])\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "\n",
    "print(f'PR AUC:{average_precision_score(y_val,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4633f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_wo_cat = LogisticRegression(penalty='l1', solver='saga', class_weight={0:1, 1:600}, random_state=42, C=0.10)\n",
    "log_reg_wo_cat.fit(X_train_low_chi, y_train)\n",
    "\n",
    "y_pred = log_reg_wo_cat.predict(X_val_proc[low_chi_cat])\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "\n",
    "print(f'PR AUC:{average_precision_score(y_val,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb_w_cat = XGBClassifier(\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.05,\n",
    "    subsample = 0.6,\n",
    "    colsample_bytree = 0.8,\n",
    "    reg_alpha = 0,\n",
    "    reg_lambda = 1,\n",
    "    scale_pos_weight = 600\n",
    ")\n",
    "\n",
    "rf_w_cat = RandomForestClassifier(n_estimators=300,\n",
    "                                   min_samples_split=10,\n",
    "                                   min_samples_leaf=3,\n",
    "                                   max_features='log2',\n",
    "                                   max_depth=7,\n",
    "                                   class_weight={0: 1.0, 1: 600.0})\n",
    "\n",
    "voting_w_cat_hard = VotingClassifier(estimators=[\n",
    "    ('xgb', xgb_w_cat), ('rf', rf_w_cat)], voting='hard'\n",
    ")\n",
    "\n",
    "voting_w_cat_hard.fit(X_train_proc, y_train)\n",
    "\n",
    "recall_macro_scorer = make_scorer(recall_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(voting_w_cat_hard, X_train_proc, y_train, cv=kfold, scoring=recall_macro_scorer)\n",
    "\n",
    "print(\"Macro Recall (per fold):\", scores)\n",
    "print(\"Mean Macro Recall:\", scores.mean())\n",
    "\n",
    "y_pred = voting_w_cat_hard.predict(X_val_proc)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "\n",
    "print(f'PR AUC:{average_precision_score(y_val,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60501feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_w_cat = XGBClassifier(\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.05,\n",
    "    subsample = 0.6,\n",
    "    colsample_bytree = 0.8,\n",
    "    reg_alpha = 0,\n",
    "    reg_lambda = 1,\n",
    "    scale_pos_weight = 600\n",
    ")\n",
    "\n",
    "rf_w_cat = RandomForestClassifier(n_estimators=300,\n",
    "                                   min_samples_split=10,\n",
    "                                   min_samples_leaf=3,\n",
    "                                   max_features='log2',\n",
    "                                   max_depth=7,\n",
    "                                   class_weight={0: 1.0, 1: 600.0})\n",
    "\n",
    "voting_w_cat_soft = VotingClassifier(estimators=[\n",
    "    ('xgb', xgb_w_cat), ('rf', rf_w_cat)], voting='soft'\n",
    ")\n",
    "\n",
    "\n",
    "voting_w_cat_soft.fit(X_train_proc, y_train)\n",
    "\n",
    "recall_macro_scorer = make_scorer(recall_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(voting_w_cat_soft, X_train_proc, y_train, cv=kfold, scoring=recall_macro_scorer)\n",
    "\n",
    "print(\"Macro Recall (per fold):\", scores)\n",
    "print(\"Mean Macro Recall:\", scores.mean())\n",
    "\n",
    "y_pred = voting_w_cat_soft.predict(X_val_proc)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "\n",
    "print(f'PR AUC:{average_precision_score(y_val,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602de53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_wo_cat = XGBClassifier(\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.05,\n",
    "    subsample = 0.8,\n",
    "    colsample_bytree = 1,\n",
    "    reg_alpha = 1,\n",
    "    reg_lambda = 1,\n",
    "    scale_pos_weight = 600\n",
    ")\n",
    "\n",
    "xgb_wo_cat.fit(X_train_proc_wo_cat, y_train)\n",
    "\n",
    "rf_wo_cat = RandomForestClassifier(n_estimators=400,\n",
    "                                   min_samples_split=5,\n",
    "                                   min_samples_leaf=3,\n",
    "                                   max_features='log2',\n",
    "                                   max_depth=7,\n",
    "                                   class_weight={0: 1.0, 1: 600.0})\n",
    "\n",
    "rf_wo_cat.fit(X_train_proc_wo_cat, y_train)\n",
    "\n",
    "voting_wo_cat_soft = VotingClassifier(estimators=[\n",
    "    ('xgb', xgb_wo_cat), ('rf', rf_wo_cat)], voting='soft'\n",
    ")\n",
    "\n",
    "voting_wo_cat_soft.fit(X_train_proc, y_train)\n",
    "\n",
    "recall_macro_scorer = make_scorer(recall_score, average='macro')\n",
    "\n",
    "scores = cross_val_score(voting_wo_cat_soft, X_train_proc, y_train, cv=kfold, scoring=recall_macro_scorer)\n",
    "\n",
    "print(\"Macro Recall (per fold):\", scores)\n",
    "print(\"Mean Macro Recall:\", scores.mean())\n",
    "\n",
    "y_pred = voting_wo_cat_soft.predict(X_val_proc)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "\n",
    "print(f'PR AUC:{average_precision_score(y_val,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b3802-6857-45ea-bb3a-b1b14d89cabc",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d938f32-3d9e-4ea4-ba30-af71d7ae171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, f1_score, precision_score\n",
    "import pandas as pd\n",
    "\n",
    "# Scoring metrics\n",
    "scorers = {\n",
    "    'recall_macro': make_scorer(recall_score, average='macro'),\n",
    "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro')\n",
    "}\n",
    "n_jobs = 24\n",
    "rf_defaults = dict(n_estimators=300, random_state=42, n_jobs=n_jobs)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400],\n",
    "    'class_weight': [\"balanced\", {0: 1.0, 1: 600.0}],\n",
    "    'max_depth': [5, 7, 10],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [3, 5],\n",
    "    'max_features': [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "def run_rf_gridsearch(X, y, kfold, label):\n",
    "    print(f\"\\n Running GridSearchCV for: {label}\")\n",
    "    rf = RandomForestClassifier(**rf_defaults)\n",
    "\n",
    "    gcv = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scorers,\n",
    "        refit=\"recall_macro\",\n",
    "        cv=kfold,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    gcv.fit(X, y)\n",
    "\n",
    "    print(f\" Best params: {gcv.best_params_}\")\n",
    "    print(f\" Best recall_macro: {gcv.best_score_:.4f}\")\n",
    "    return gcv.best_estimator_, gcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04910d25-3c24-45b9-9d4a-9b2bea7e4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without categorical columns\n",
    "best_rf_wo, gcv_wo = run_rf_gridsearch(X_train_proc_wo_cat, y_train, kfold, \"WITHOUT cat_cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5be11d-ae78-45e5-8da6-29d90e4bde44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With categorical columns\n",
    "best_rf_with, gcv_with = run_rf_gridsearch(X_train_proc, y_train, kfold, \"WITH cat_cols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db82f6-2b18-46ed-843a-69ac093470aa",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83f2ff-7386-47b2-b9ca-39edfdab4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_smote_wo_cat, y_smote = sm.fit_resample(X_train_proc_wo_cat, y_train)\n",
    "X_smote, y_smote = sm.fit_resample(X_train_proc, y_train)\n",
    "print(\"After SMOTE without categorical columns:\", X_smote_wo_cat.shape, y_smote.value_counts().to_dict())\n",
    "print(\"After SMOTE all columns:\", X_smote.shape, y_smote.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b5110-a098-4af5-b271-9865a77e6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, average_precision_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def run_xgb_gridsearch(X, y, cv, verbose=2, n_jobs=20):\n",
    "    xgb_base = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 4, 5, 6],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.5, 1.0],\n",
    "        'reg_lambda': [0.5, 1.0, 2.0],\n",
    "        'scale_pos_weight': [1.0, 600.0]\n",
    "    }\n",
    "\n",
    "    scorers = {\n",
    "        'recall_macro': make_scorer(recall_score, average='macro'),\n",
    "        'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "        'pr_auc': make_scorer(average_precision_score, needs_proba=True)\n",
    "    }\n",
    "\n",
    "    gcv = GridSearchCV(\n",
    "        estimator=xgb_base,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scorers,\n",
    "        refit='recall_macro',\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=verbose,\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    gcv.fit(X, y)\n",
    "\n",
    "    results = pd.DataFrame(gcv.cv_results_).sort_values(\"mean_test_recall_macro\", ascending=False)\n",
    "\n",
    "    top_cols = [\n",
    "        'param_max_depth', 'param_learning_rate', 'param_subsample', 'param_colsample_bytree',\n",
    "        'param_reg_alpha', 'param_reg_lambda', 'param_scale_pos_weight',\n",
    "        'mean_test_recall_macro', 'mean_test_f1_macro', 'mean_test_pr_auc'\n",
    "    ]\n",
    "\n",
    "    print(results[top_cols].head(10))\n",
    "    return gcv, results[top_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaa510-4ec1-42f3-ab0a-3f37a626f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With full features\n",
    "gcv_full, results_full = run_xgb_gridsearch(X_smote, y_smote, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818c35a-acfe-4cb8-9d05-3a13c9023c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without categorical features\n",
    "gcv_wo_cat, results_wo_cat = run_xgb_gridsearch(X_smote_wo_cat, y_smote, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b55cc-2fc6-4e61-adbe-a137c46af197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
