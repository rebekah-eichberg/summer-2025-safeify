{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4423cf2-f22c-4e07-947d-66f0a22ce9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff1e09c-0289-4662-97ea-0e58acb61179",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Data/amazon_meta.json'  \n",
    "amazon_df = pd.read_json(file_path, lines=True, compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61aab795-d2ee-4cda-9fff-88931bd37774",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_train = 'Data/train.parquet'  \n",
    "file_path_test = 'Data/test.parquet'  \n",
    "df_train = pd.read_parquet(file_path_train)\n",
    "df_test = pd.read_parquet(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4ba094-d176-4460-beee-051b3ccdde7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_asins = df_train['asin'].tolist() + df_test['asin'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc32636c-e058-46fa-9418-59945fcd29b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201370"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_asins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ee3375-2176-444c-8f26-b2fbfd224c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(633883, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c56618-abac-4909-a098-8e16f8b6f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df_filtered = amazon_df[amazon_df['asin'].isin(all_asins)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43477c0-c239-4c5a-95fa-5653920901d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204604, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f929759-e67d-4e12-b7d2-b71fa2c29142",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df_unique = amazon_df_filtered.drop_duplicates(subset='asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83bcf7ba-262a-45b5-9c91-611db60139d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201370, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0952af57-ab08-493d-bfb0-55d76b09120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "certification_labels = [\n",
    "    \"FDA approved\",\n",
    "    \"FDA certified\",\n",
    "    \"FDA registered\",\n",
    "    \"FDA compliant\",\n",
    "    \"ISO certified\",\n",
    "    \"CE marked\",\n",
    "    \"CE certified\",\n",
    "    \"GMP certified\",\n",
    "    \"UL certified\",\n",
    "    \"CPSIA compliant\",\n",
    "    \"ASTM F963 compliant\",\n",
    "    \"Childrens Product Certificate (CPC)\",\n",
    "    \"EN 71 compliant\",\n",
    "    \"REACH compliant\",\n",
    "    \"Declaration of Conformity (DoC)\",\n",
    "    \"FCC compliant\",\n",
    "    \"CCC Mark\",\n",
    "    \"ISO 8124 compliant\",\n",
    "    \"UKCA compliant\",\n",
    "    \"Canada Consumer Product Safety Act (CCPSA) compliant\",\n",
    "    \"ST Mark compliant\",\n",
    "    \"RoHS compliant\",\n",
    "    \"WEEE compliant\"\n",
    "]\n",
    "\n",
    "non_toxic_labels = [\n",
    "    \"third-party tested\",\n",
    "    \"lab tested\",\n",
    "    \"non-toxic\",\n",
    "    \"PVC free\",\n",
    "    \"BPA free\",\n",
    "    \"phthalate free\",\n",
    "    \"lead free\",\n",
    "    \"formaldehyde free\",\n",
    "    \"latex free\",\n",
    "]\n",
    "\n",
    "age_appropriate_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "046e7ae3-7217-441e-98f3-06d62b1cccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Betul\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Setup\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "#classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "#classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-large-mnli\", device=0)\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\", device=0)\n",
    "\n",
    "\n",
    "# Simulate batch processing\n",
    "def batched_zero_shot(df, text_cols=('description', 'feature'), labels=None, threshold=0.97, batch_size=16):\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"Processing batches\"):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "\n",
    "        # Pre-process and classify each row\n",
    "        for _, row in batch_df.iterrows():\n",
    "            desc_text = row[text_cols[0]]\n",
    "            feat_text = row[text_cols[1]]\n",
    "\n",
    "            desc_labels, desc_score = process_text(desc_text, labels, threshold)\n",
    "            feat_labels, feat_score = process_text(feat_text, labels, threshold)\n",
    "\n",
    "            combined_labels = []\n",
    "            if desc_labels:\n",
    "                combined_labels.extend(desc_labels)\n",
    "            if feat_labels:\n",
    "                combined_labels.extend(feat_labels)\n",
    "\n",
    "            # Deduplicate and store\n",
    "            combined_labels = list(dict.fromkeys(combined_labels)) if combined_labels else None\n",
    "            all_labels.append(combined_labels)\n",
    "            all_scores.append(max(desc_score, feat_score))\n",
    "\n",
    "    return all_labels, all_scores\n",
    "\n",
    "# Helper function to handle single text input\n",
    "def process_text(text, labels, threshold):\n",
    "    # Handle missing, list, or bad formats\n",
    "    if isinstance(text, list):\n",
    "        text = \" \".join(str(x) for x in text if x).strip()\n",
    "    elif not isinstance(text, str):\n",
    "        text = str(text).strip()\n",
    "\n",
    "    if not text or text == '[]':\n",
    "        return None, 0.0\n",
    "\n",
    "    try:\n",
    "        result = classifier(text, labels, multi_label=True)\n",
    "        scores = result[\"scores\"]\n",
    "        high_conf = [label for label, score in zip(result[\"labels\"], scores) if score > threshold]\n",
    "        return high_conf if high_conf else None, max(scores)\n",
    "    except Exception as e:\n",
    "        return None, 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d283861a-0573-4e14-bb82-592a156cc4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|                                                                      | 0/125 [00:00<?, ?it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Processing batches: 100%|████████████████████████████████████████████████████████████| 125/125 [08:07<00:00,  3.90s/it]\n"
     ]
    }
   ],
   "source": [
    "sample_df['certification_labels'], sample_df['max_cert_score'] = batched_zero_shot(\n",
    "    sample_df,\n",
    "    text_cols=('description', 'feature'),\n",
    "    labels=certification_labels,\n",
    "    threshold=0.97,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e158043-701e-4ddf-a80e-67499a454603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with non-empty certifications: 62 / 1000\n",
      "Percentage: 6.20%\n"
     ]
    }
   ],
   "source": [
    "# Total number of rows\n",
    "total_rows = len(sample_df)\n",
    "\n",
    "# Number of rows with non-empty certifications\n",
    "non_empty_cert = sample_df['certification_labels'].apply(lambda x: bool(x)).sum()\n",
    "\n",
    "# Percentage\n",
    "percentage_cert = non_empty_cert / total_rows\n",
    "\n",
    "print(f\"Number of rows with non-empty certifications: {non_empty_cert} / {total_rows}\")\n",
    "print(f\"Percentage: {percentage_cert:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "018ba0d5-3e2c-4138-a3b4-4aabff743438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_zero_shot(df, text_cols=('description', 'feature'), labels=None, threshold=0.97, batch_size=16):\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"Processing batches\"):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "\n",
    "        # Collect cleaned text for description and feature\n",
    "        desc_batch = [clean_text(row[text_cols[0]]) for _, row in batch_df.iterrows()]\n",
    "        feat_batch = [clean_text(row[text_cols[1]]) for _, row in batch_df.iterrows()]\n",
    "\n",
    "        try:\n",
    "            desc_results = classifier(desc_batch, labels, multi_label=True)\n",
    "            feat_results = classifier(feat_batch, labels, multi_label=True)\n",
    "        except Exception as e:\n",
    "            desc_results = [None] * len(batch_df)\n",
    "            feat_results = [None] * len(batch_df)\n",
    "\n",
    "        for desc_res, feat_res in zip(desc_results, feat_results):\n",
    "            labels_d, score_d = parse_result(desc_res, labels, threshold)\n",
    "            labels_f, score_f = parse_result(feat_res, labels, threshold)\n",
    "\n",
    "            combined = list(dict.fromkeys((labels_d or []) + (labels_f or []))) or None\n",
    "            all_labels.append(combined)\n",
    "            all_scores.append(max(score_d, score_f))\n",
    "\n",
    "    return all_labels, all_scores\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, list):\n",
    "        return \" \".join(str(x) for x in text if x).strip()\n",
    "    elif not isinstance(text, str):\n",
    "        return str(text).strip()\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def parse_result(result, labels, threshold):\n",
    "    if not result or not isinstance(result, dict):\n",
    "        return None, 0.0\n",
    "    scores = result[\"scores\"]\n",
    "    high_conf = [label for label, score in zip(result[\"labels\"], scores) if score > threshold]\n",
    "    return high_conf if high_conf else None, max(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1fc1c-3ba5-4f23-a4b6-dd6b2246b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█████████                                             | 1058/6293 [1:11:14<3:43:11,  2.56s/it]"
     ]
    }
   ],
   "source": [
    "amazon_df_unique['certification_labels'], amazon_df_unique['max_cert_score'] = batched_zero_shot(\n",
    "    amazon_df_unique,\n",
    "    text_cols=('description', 'feature'),\n",
    "    labels=certification_labels,\n",
    "    threshold=0.97,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1e949-9b3b-492e-a419-cb1266de8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of rows\n",
    "total_rows = len(amazon_df_unique)\n",
    "\n",
    "# Number of rows with non-empty certifications\n",
    "non_empty_cert = amazon_df_unique['certification_labels'].apply(lambda x: bool(x)).sum()\n",
    "\n",
    "# Percentage\n",
    "percentage_cert = non_empty_cert / total_rows\n",
    "\n",
    "print(f\"Number of rows with non-empty certifications: {non_empty_cert} / {total_rows}\")\n",
    "print(f\"Percentage: {percentage_cert:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a064f48-ced5-425d-be72-31ac9229e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df_unique['certification_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe667932-57c9-4b17-bc2f-9009c5a64dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "amazon_df_unique.to_pickle(\"Data/amazon_df_cert_features2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb77c4-6a2e-4aa4-861b-6623681b12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df_unique['non_toxic_labels'], amazon_df_unique['max_non_toxic_score'] = batched_zero_shot(\n",
    "    amazon_df_unique,\n",
    "    text_cols=('description', 'feature'),\n",
    "    labels=non_toxic_labels,\n",
    "    threshold=0.97,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d58a4c-7beb-48c5-b3f6-06ca6e47c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of rows\n",
    "total_rows = len(sample_df)\n",
    "\n",
    "# Number of rows with non-empty labels\n",
    "non_empty_tox = sample_df['non_toxic_labels'].apply(lambda x: bool(x)).sum()\n",
    "\n",
    "# Percentage\n",
    "percentage_tox = non_empty_tox / total_rows\n",
    "\n",
    "print(f\"Number of rows with non-empty non toxic labels: {non_empty_tox} / {total_rows}\")\n",
    "print(f\"Percentage: {percentage_tox:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3874aaa-6814-4b38-9e22-4cd06b6c0163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
