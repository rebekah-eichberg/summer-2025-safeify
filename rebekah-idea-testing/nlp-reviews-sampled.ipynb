{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5257000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')       \n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt_tab')  \n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helper_functions import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Recall data\n",
    "\n",
    "# Paths to all three files\n",
    "recall_files = [\n",
    "    \"../Data/Current Version of Toys Incidence+Recall/Toysandchildren_ArtsandCrafts.csv\",\n",
    "    \"../Data/Current Version of Toys Incidence+Recall/Toysandchildren_Riding_Toys.csv\",\n",
    "    \"../Data/Current Version of Toys Incidence+Recall/Toysandchildren_Toys.csv\"\n",
    "]\n",
    "\n",
    "recall_dfs = [load_clean_csv(path) for path in recall_files]\n",
    "recalls_df = pd.concat(recall_dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in reviews data\n",
    "reviews_df = pd.read_pickle('reviews_raw.pkl')\n",
    "reviews_df['asin'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcde81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model to create embeddings on incident description text\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the recalls data, embed the incident description\n",
    "combined_indicent_text = \" \".join(recalls_df['Incident Description'].dropna().tolist())\n",
    "incident_desc_embedding = model.encode(combined_indicent_text)\n",
    "incident_desc_embedding = np.array(incident_desc_embedding).reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ecf213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the complaints data to remove stop words and get down to lemm\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "incidents = recalls_df['Incident Description'].dropna().astype(str)\n",
    "all_tokens = incidents.apply(preprocess)\n",
    "\n",
    "# Flatten to single list of tokens\n",
    "flattened_tokens = [token for sublist in all_tokens for token in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc280ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: count top words\n",
    "word_freq = Counter(flattened_tokens)\n",
    "top_words = word_freq.most_common(20)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c32d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(word_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c391b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat gpt returns the negative words from word_freq\n",
    "negative_words = [\n",
    "    'choke', 'hazard', 'dangerous', 'danger', 'dermatitis', 'bother',\n",
    "    'accidentally', 'ingest', 'notorious', 'toxic', 'warn', 'cause',\n",
    "    'allergic', 'reaction', 'rash', 'sensitization', 'occur',\n",
    "    'seek', 'medical', 'die', 'poison', 'elevated', 'burn', 'urgent',\n",
    "    'treatment', 'pinch', 'pinched', 'slice', 'lacerate', 'moldy',\n",
    "    'waste', 'black', 'spot', 'bleed', 'miss', 'sharp', 'metal',\n",
    "    'damage', 'difficulty', 'injure', 'inconvenience', 'serious',\n",
    "    'return', 'disagree', 'concern', 'broken', 'shatter', 'remove',\n",
    "    'unsafe', 'terrible', 'odor', 'infuriate', 'infection', 'irritation',\n",
    "    'cough', 'irritate', 'headache', 'chemical', 'blister', 'bleeding',\n",
    "    'sick', 'asthma', 'attack', 'pain', 'scar', 'nasty', 'impact',\n",
    "    'accident', 'penetrate', 'trapping', 'ignite', 'overheat',\n",
    "    'fire', 'fail', 'explode', 'burning', 'puncture', 'swollen',\n",
    "    'wound', 'injury', 'hurt', 'sore', 'contaminate', 'vomit', 'bleed',\n",
    "    'allergy', 'toxic', 'deadly', 'severe', 'dyshidrotic', 'eczema',\n",
    "    'bacterial', 'disapointing', 'poorly', 'redness', 'burnt',\n",
    "    'complain', 'bad', 'dangerously', 'emergency', 'hospital'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72982176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way is to do thematic classification\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "test_embeddings = model.encode(recalls_df['Incident Description'].tolist())\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "recalls_df['cluster'] = kmeans.fit_predict(test_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_num in range(5):\n",
    "    print(f\"\\nCluster {cluster_num} samples:\")\n",
    "    sample_texts = recalls_df[recalls_df['cluster'] == cluster_num]['Incident Description'].head(5)\n",
    "    for text in sample_texts:\n",
    "        print(\"-\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb09301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def get_top_words(texts, n=10):\n",
    "    all_words = ' '.join(texts).lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', all_words)\n",
    "    stopwords = set(['the', 'and', 'is', 'to', 'in', 'of', 'a', 'for', 'on', 'with', 'it', 'this', 'that'])  # add more stopwords as needed\n",
    "    filtered_words = [w for w in words if w not in stopwords and len(w) > 2]\n",
    "    common_words = Counter(filtered_words).most_common(n)\n",
    "    return [w[0] for w in common_words]\n",
    "\n",
    "for cluster_num in range(5):\n",
    "    texts = recalls_df[recalls_df['cluster'] == cluster_num]['Incident Description']\n",
    "    print(f\"\\nTop words for cluster {cluster_num}: {get_top_words(texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47776dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e6da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(incidents)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=40, random_state=0)\n",
    "lda.fit(X)\n",
    "\n",
    "# Get keywords per topic\n",
    "words = vectorizer.get_feature_names_out()\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    top_words = [words[i] for i in topic.argsort()[-10:]]\n",
    "    print(f\"Topic {i+1}: {top_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a smaller reviews dataframe\n",
    "reviews_sample_df = reviews_df.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should we be dropping duplicates?\n",
    "reviews_sample_df[reviews_sample_df.duplicated(['asin', 'reviewText', 'summary'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a850a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na in reviewtext, asin and summary column\n",
    "reviews_sample_df = reviews_sample_df[['asin', 'reviewText', 'summary' ,'overall']].copy()\n",
    "reviews_sample_df = reviews_sample_df.dropna(subset=['asin','reviewText', 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf59881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip possible leading or trailing white space\n",
    "reviews_model_df = reviews_sample_df[reviews_sample_df['reviewText'].str.strip() != '']\n",
    "reviews_model_df = reviews_model_df[reviews_model_df['summary'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da6cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the reviewText\n",
    "reviews_embeddings = model.encode(\n",
    "    reviews_model_df['reviewText'].tolist(),\n",
    "    batch_size=32,    #32, 64, 128 based on memory           \n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True        \n",
    ")\n",
    "reviews_model_df['reviews_embeddings'] = [vec for vec in reviews_embeddings]\n",
    "reviews_embeddings = np.array(reviews_embeddings)\n",
    "reviews_embeddings = np.vstack(reviews_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the summary column\n",
    "# reviews_model_df['summary_embedding'] = reviews_model_df['summary'].apply(lambda x: model.encode(x, show_progress_bar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac999eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take cosine similarity between reviews and the incident description embedding\n",
    "review_similarities = cosine_similarity(incident_desc_embedding, reviews_embeddings)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the cosine similarities between review and incidents on the main df\n",
    "reviews_model_df['review_cosine_sim'] = review_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d29b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of reviews per product\n",
    "reviews_model_df.groupby('asin')['reviewText'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56cb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_df = reviews_model_df.groupby('asin')['review_cosine_sim'].agg(\n",
    "    mean_similarity = 'mean',\n",
    "    max_similarity = 'max'\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af16565",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef16580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# classify the summary in the reviews data\n",
    "batch_size = 8\n",
    "texts = reviews_model_df['summary'].fillna('').tolist()\n",
    "original_indices = reviews_model_df.index.tolist()\n",
    "\n",
    "scored_rows = []\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    batch_indices = original_indices[i:i+batch_size]\n",
    "    \n",
    "    scores = classify_batch_all_scores(batch)\n",
    "    \n",
    "    for idx, score_dict in zip(batch_indices, scores):\n",
    "        scored_rows.append((idx, score_dict))\n",
    "\n",
    "label_scores_df = pd.DataFrame(\n",
    "    [score_dict for idx, score_dict in scored_rows],\n",
    "    index=[idx for idx, score_dict in scored_rows]\n",
    ")\n",
    "\n",
    "reviews_model_df = reviews_model_df.join(label_scores_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aedb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac127eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other features to consider\n",
    "# avg_review_length, avg_sentence_count, punctuation_density\n",
    "# capture sentiment like tone or emotion not fully captured in embedding: avg_sentiment_score\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply VADER to each review\n",
    "def get_sentiment_scores(text):\n",
    "    return analyzer.polarity_scores(text)\n",
    "\n",
    "sentiment_df = final_model_df['reviewText'].apply(get_sentiment_scores).apply(pd.Series)\n",
    "\n",
    "# Add to main dataframe\n",
    "final_model_df = pd.concat([final_model_df, sentiment_df], axis=1)\n",
    "\n",
    "# Group by ASIN and aggregate\n",
    "asin_sentiment = final_model_df.groupby('asin')[['compound', 'pos', 'neu', 'neg']].mean().reset_index()\n",
    "\n",
    "# (Optional) Add std deviation if you want:\n",
    "sentiment_std = final_model_df.groupby('asin')['compound'].std().reset_index().rename(columns={'compound': 'compound_std'})\n",
    "asin_sentiment = asin_sentiment.merge(sentiment_std, on='asin', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576ec59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
