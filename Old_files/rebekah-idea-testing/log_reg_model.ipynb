{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4d8bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    average_precision_score, precision_score, recall_score, f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f0233",
   "metadata": {},
   "source": [
    "Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "693fa31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('../train_final_v3.parquet')\n",
    "val_df = pd.read_parquet('../validationA_v3.parquet')\n",
    "cal_df = pd.read_parquet('../validationB_v3.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20c792",
   "metadata": {},
   "source": [
    "PreProcess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44537142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name of embedding columns\n",
    "dfs = [train_df, val_df, cal_df]\n",
    "\n",
    "for df in dfs:\n",
    "    # rename embed_{n} as summary_embedding_{n}\n",
    "    df.rename(columns={f\"embed_{i}\": f\"summary_embedding_{i}\" for i in range(384)}, inplace=True)\n",
    "    # rename embedding_{n} as reviewtext_embedding_{n}\n",
    "    df.rename(columns={f\"embedding_{i}\": f\"reviewtext_embedding_{i}\" for i in range(384)}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0664bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_targets(dfs, target_column='match'):\n",
    "    targets = []\n",
    "    for df in dfs:\n",
    "        targets.append(df[target_column])\n",
    "        df.drop(columns=[target_column], inplace=True)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba8098ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract target and drop from design matrix\n",
    "dfs = [train_df, val_df, cal_df]\n",
    "targets = extract_targets(dfs)\n",
    "\n",
    "train_y, val_y, cal_y = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11b34918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-embedding features\n",
    "begin_features = train_df.columns[:16].to_list()\n",
    "end_features = train_df.columns[-6:].to_list()\n",
    "non_embedding_features = begin_features + end_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5566e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "categorical_features = 'category'\n",
    "\n",
    "# change and check data types \n",
    "for df in dfs:\n",
    "    df['product_lifespan'] = df['product_lifespan'].dt.days\n",
    "    df['missing_price'] = df['missing_price'].astype(int)\n",
    "    df.drop(['min_date', 'max_date'], axis=1, inplace=True)\n",
    "\n",
    "categorical_cols = train_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = train_df.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76962942",
   "metadata": {},
   "source": [
    "EDA on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce339272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_price</th>\n",
       "      <th>item_rank</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>min_rating</th>\n",
       "      <th>percent_positive</th>\n",
       "      <th>percent_negative</th>\n",
       "      <th>avg_verified_reviewers</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>product_lifespan</th>\n",
       "      <th>...</th>\n",
       "      <th>unique_reviewer_count</th>\n",
       "      <th>avg_reviews_per_day</th>\n",
       "      <th>reviews_per_product</th>\n",
       "      <th>avg_review_length_words</th>\n",
       "      <th>mean_sentiment_score</th>\n",
       "      <th>mean_complaint_similarity</th>\n",
       "      <th>mean_shipping_similarity</th>\n",
       "      <th>max_complaint_similarity</th>\n",
       "      <th>shipping_similarity_at_max_complaint</th>\n",
       "      <th>sentiment_score_at_max_complaint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missing_price</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397232</td>\n",
       "      <td>-0.073722</td>\n",
       "      <td>-0.084188</td>\n",
       "      <td>-0.066885</td>\n",
       "      <td>0.059782</td>\n",
       "      <td>-0.080962</td>\n",
       "      <td>-0.094594</td>\n",
       "      <td>-0.263965</td>\n",
       "      <td>-0.132964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076755</td>\n",
       "      <td>-0.035336</td>\n",
       "      <td>-0.075929</td>\n",
       "      <td>0.081868</td>\n",
       "      <td>-0.059014</td>\n",
       "      <td>0.023654</td>\n",
       "      <td>-0.009715</td>\n",
       "      <td>-0.086209</td>\n",
       "      <td>-0.078643</td>\n",
       "      <td>-0.024765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_rank</th>\n",
       "      <td>0.397232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.103719</td>\n",
       "      <td>-0.284773</td>\n",
       "      <td>-0.093563</td>\n",
       "      <td>0.086678</td>\n",
       "      <td>-0.151444</td>\n",
       "      <td>-0.142030</td>\n",
       "      <td>-0.609545</td>\n",
       "      <td>-0.391541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199884</td>\n",
       "      <td>-0.044102</td>\n",
       "      <td>-0.196587</td>\n",
       "      <td>0.136703</td>\n",
       "      <td>-0.109818</td>\n",
       "      <td>0.055039</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>-0.361435</td>\n",
       "      <td>-0.263765</td>\n",
       "      <td>0.014220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rating</th>\n",
       "      <td>-0.073722</td>\n",
       "      <td>-0.103719</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.797841</td>\n",
       "      <td>0.928199</td>\n",
       "      <td>-0.902056</td>\n",
       "      <td>0.103396</td>\n",
       "      <td>0.029055</td>\n",
       "      <td>0.062871</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>0.027177</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>-0.116737</td>\n",
       "      <td>0.687027</td>\n",
       "      <td>-0.274461</td>\n",
       "      <td>-0.187014</td>\n",
       "      <td>-0.179334</td>\n",
       "      <td>-0.119191</td>\n",
       "      <td>0.512224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_rating</th>\n",
       "      <td>-0.084188</td>\n",
       "      <td>-0.284773</td>\n",
       "      <td>0.797841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739617</td>\n",
       "      <td>-0.721084</td>\n",
       "      <td>0.050736</td>\n",
       "      <td>-0.075741</td>\n",
       "      <td>0.183490</td>\n",
       "      <td>0.248919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075076</td>\n",
       "      <td>0.024598</td>\n",
       "      <td>0.073721</td>\n",
       "      <td>-0.073316</td>\n",
       "      <td>0.551026</td>\n",
       "      <td>-0.207011</td>\n",
       "      <td>-0.163593</td>\n",
       "      <td>0.082534</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>0.328040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_positive</th>\n",
       "      <td>-0.066885</td>\n",
       "      <td>-0.093563</td>\n",
       "      <td>0.928199</td>\n",
       "      <td>0.739617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.802110</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.051160</td>\n",
       "      <td>0.026545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.025616</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>-0.105495</td>\n",
       "      <td>0.643896</td>\n",
       "      <td>-0.255409</td>\n",
       "      <td>-0.175981</td>\n",
       "      <td>-0.165793</td>\n",
       "      <td>-0.110991</td>\n",
       "      <td>0.477634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_negative</th>\n",
       "      <td>0.059782</td>\n",
       "      <td>0.086678</td>\n",
       "      <td>-0.902056</td>\n",
       "      <td>-0.721084</td>\n",
       "      <td>-0.802110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084272</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>-0.029223</td>\n",
       "      <td>-0.030873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>-0.022650</td>\n",
       "      <td>-0.011240</td>\n",
       "      <td>0.066051</td>\n",
       "      <td>-0.646173</td>\n",
       "      <td>0.256231</td>\n",
       "      <td>0.196444</td>\n",
       "      <td>0.167256</td>\n",
       "      <td>0.127280</td>\n",
       "      <td>-0.483966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_verified_reviewers</th>\n",
       "      <td>-0.080962</td>\n",
       "      <td>-0.151444</td>\n",
       "      <td>0.103396</td>\n",
       "      <td>0.050736</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>-0.084272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329849</td>\n",
       "      <td>0.287963</td>\n",
       "      <td>-0.105624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.033327</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>-0.338600</td>\n",
       "      <td>0.109111</td>\n",
       "      <td>-0.056607</td>\n",
       "      <td>0.114678</td>\n",
       "      <td>-0.046647</td>\n",
       "      <td>0.080529</td>\n",
       "      <td>0.082968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_date</th>\n",
       "      <td>-0.094594</td>\n",
       "      <td>-0.142030</td>\n",
       "      <td>0.029055</td>\n",
       "      <td>-0.075741</td>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.329849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519009</td>\n",
       "      <td>-0.638843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116391</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>-0.120776</td>\n",
       "      <td>-0.295380</td>\n",
       "      <td>0.077075</td>\n",
       "      <td>-0.035293</td>\n",
       "      <td>0.128746</td>\n",
       "      <td>-0.191535</td>\n",
       "      <td>-0.020447</td>\n",
       "      <td>0.088981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_date</th>\n",
       "      <td>-0.263965</td>\n",
       "      <td>-0.609545</td>\n",
       "      <td>0.062871</td>\n",
       "      <td>0.183490</td>\n",
       "      <td>0.051160</td>\n",
       "      <td>-0.029223</td>\n",
       "      <td>0.287963</td>\n",
       "      <td>0.519009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.326040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.041838</td>\n",
       "      <td>0.166758</td>\n",
       "      <td>-0.253813</td>\n",
       "      <td>0.105516</td>\n",
       "      <td>-0.043318</td>\n",
       "      <td>0.075688</td>\n",
       "      <td>0.273420</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.002470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_lifespan</th>\n",
       "      <td>-0.132964</td>\n",
       "      <td>-0.391541</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>0.248919</td>\n",
       "      <td>0.026545</td>\n",
       "      <td>-0.030873</td>\n",
       "      <td>-0.105624</td>\n",
       "      <td>-0.638843</td>\n",
       "      <td>0.326040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281507</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>0.283666</td>\n",
       "      <td>0.098239</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.074266</td>\n",
       "      <td>0.457925</td>\n",
       "      <td>0.248697</td>\n",
       "      <td>-0.096188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_bots_per_asin</th>\n",
       "      <td>-0.072273</td>\n",
       "      <td>-0.140241</td>\n",
       "      <td>0.041984</td>\n",
       "      <td>0.056458</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>-0.034799</td>\n",
       "      <td>0.013744</td>\n",
       "      <td>-0.057167</td>\n",
       "      <td>0.113362</td>\n",
       "      <td>0.165257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448655</td>\n",
       "      <td>0.171682</td>\n",
       "      <td>0.454697</td>\n",
       "      <td>-0.026401</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>-0.004584</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.184230</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>-0.015611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_reviewer_count</th>\n",
       "      <td>-0.076755</td>\n",
       "      <td>-0.199884</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>0.075076</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>-0.116391</td>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.281507</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.987056</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.016020</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>-0.025254</td>\n",
       "      <td>0.312837</td>\n",
       "      <td>0.158865</td>\n",
       "      <td>-0.072412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_reviews_per_day</th>\n",
       "      <td>-0.035336</td>\n",
       "      <td>-0.044102</td>\n",
       "      <td>0.027177</td>\n",
       "      <td>0.024598</td>\n",
       "      <td>0.025616</td>\n",
       "      <td>-0.022650</td>\n",
       "      <td>0.033327</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>0.041838</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>-0.078165</td>\n",
       "      <td>0.039792</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.036032</td>\n",
       "      <td>0.023296</td>\n",
       "      <td>0.044437</td>\n",
       "      <td>0.028822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_product</th>\n",
       "      <td>-0.075929</td>\n",
       "      <td>-0.196587</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.073721</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>-0.011240</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>-0.120776</td>\n",
       "      <td>0.166758</td>\n",
       "      <td>0.283666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987056</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.015652</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>-0.025299</td>\n",
       "      <td>0.309501</td>\n",
       "      <td>0.156456</td>\n",
       "      <td>-0.071260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_review_length_words</th>\n",
       "      <td>0.081868</td>\n",
       "      <td>0.136703</td>\n",
       "      <td>-0.116737</td>\n",
       "      <td>-0.073316</td>\n",
       "      <td>-0.105495</td>\n",
       "      <td>0.066051</td>\n",
       "      <td>-0.338600</td>\n",
       "      <td>-0.295380</td>\n",
       "      <td>-0.253813</td>\n",
       "      <td>0.098239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>-0.078165</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.154807</td>\n",
       "      <td>0.148146</td>\n",
       "      <td>-0.162734</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>-0.117527</td>\n",
       "      <td>-0.117818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_sentiment_score</th>\n",
       "      <td>-0.059014</td>\n",
       "      <td>-0.109818</td>\n",
       "      <td>0.687027</td>\n",
       "      <td>0.551026</td>\n",
       "      <td>0.643896</td>\n",
       "      <td>-0.646173</td>\n",
       "      <td>0.109111</td>\n",
       "      <td>0.077075</td>\n",
       "      <td>0.105516</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016020</td>\n",
       "      <td>0.039792</td>\n",
       "      <td>0.015652</td>\n",
       "      <td>-0.154807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221099</td>\n",
       "      <td>-0.118711</td>\n",
       "      <td>-0.132738</td>\n",
       "      <td>-0.067076</td>\n",
       "      <td>0.722860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_complaint_similarity</th>\n",
       "      <td>0.023654</td>\n",
       "      <td>0.055039</td>\n",
       "      <td>-0.274461</td>\n",
       "      <td>-0.207011</td>\n",
       "      <td>-0.255409</td>\n",
       "      <td>0.256231</td>\n",
       "      <td>-0.056607</td>\n",
       "      <td>-0.035293</td>\n",
       "      <td>-0.043318</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.148146</td>\n",
       "      <td>-0.221099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.596156</td>\n",
       "      <td>0.652085</td>\n",
       "      <td>0.401017</td>\n",
       "      <td>-0.186382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_shipping_similarity</th>\n",
       "      <td>-0.009715</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>-0.187014</td>\n",
       "      <td>-0.163593</td>\n",
       "      <td>-0.175981</td>\n",
       "      <td>0.196444</td>\n",
       "      <td>0.114678</td>\n",
       "      <td>0.128746</td>\n",
       "      <td>0.075688</td>\n",
       "      <td>-0.074266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025254</td>\n",
       "      <td>0.036032</td>\n",
       "      <td>-0.025299</td>\n",
       "      <td>-0.162734</td>\n",
       "      <td>-0.118711</td>\n",
       "      <td>0.596156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357910</td>\n",
       "      <td>0.686648</td>\n",
       "      <td>-0.095049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_complaint_similarity</th>\n",
       "      <td>-0.086209</td>\n",
       "      <td>-0.361435</td>\n",
       "      <td>-0.179334</td>\n",
       "      <td>0.082534</td>\n",
       "      <td>-0.165793</td>\n",
       "      <td>0.167256</td>\n",
       "      <td>-0.046647</td>\n",
       "      <td>-0.191535</td>\n",
       "      <td>0.273420</td>\n",
       "      <td>0.457925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312837</td>\n",
       "      <td>0.023296</td>\n",
       "      <td>0.309501</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>-0.132738</td>\n",
       "      <td>0.652085</td>\n",
       "      <td>0.357910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606034</td>\n",
       "      <td>-0.254983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shipping_similarity_at_max_complaint</th>\n",
       "      <td>-0.078643</td>\n",
       "      <td>-0.263765</td>\n",
       "      <td>-0.119191</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>-0.110991</td>\n",
       "      <td>0.127280</td>\n",
       "      <td>0.080529</td>\n",
       "      <td>-0.020447</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.248697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158865</td>\n",
       "      <td>0.044437</td>\n",
       "      <td>0.156456</td>\n",
       "      <td>-0.117527</td>\n",
       "      <td>-0.067076</td>\n",
       "      <td>0.401017</td>\n",
       "      <td>0.686648</td>\n",
       "      <td>0.606034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.145711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment_score_at_max_complaint</th>\n",
       "      <td>-0.024765</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>0.512224</td>\n",
       "      <td>0.328040</td>\n",
       "      <td>0.477634</td>\n",
       "      <td>-0.483966</td>\n",
       "      <td>0.082968</td>\n",
       "      <td>0.088981</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>-0.096188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072412</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>-0.071260</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>0.722860</td>\n",
       "      <td>-0.186382</td>\n",
       "      <td>-0.095049</td>\n",
       "      <td>-0.254983</td>\n",
       "      <td>-0.145711</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      missing_price  item_rank  avg_rating  \\\n",
       "missing_price                              1.000000   0.397232   -0.073722   \n",
       "item_rank                                  0.397232   1.000000   -0.103719   \n",
       "avg_rating                                -0.073722  -0.103719    1.000000   \n",
       "min_rating                                -0.084188  -0.284773    0.797841   \n",
       "percent_positive                          -0.066885  -0.093563    0.928199   \n",
       "percent_negative                           0.059782   0.086678   -0.902056   \n",
       "avg_verified_reviewers                    -0.080962  -0.151444    0.103396   \n",
       "min_date                                  -0.094594  -0.142030    0.029055   \n",
       "max_date                                  -0.263965  -0.609545    0.062871   \n",
       "product_lifespan                          -0.132964  -0.391541    0.024453   \n",
       "num_bots_per_asin                         -0.072273  -0.140241    0.041984   \n",
       "unique_reviewer_count                     -0.076755  -0.199884    0.011853   \n",
       "avg_reviews_per_day                       -0.035336  -0.044102    0.027177   \n",
       "reviews_per_product                       -0.075929  -0.196587    0.011709   \n",
       "avg_review_length_words                    0.081868   0.136703   -0.116737   \n",
       "mean_sentiment_score                      -0.059014  -0.109818    0.687027   \n",
       "mean_complaint_similarity                  0.023654   0.055039   -0.274461   \n",
       "mean_shipping_similarity                  -0.009715   0.004621   -0.187014   \n",
       "max_complaint_similarity                  -0.086209  -0.361435   -0.179334   \n",
       "shipping_similarity_at_max_complaint      -0.078643  -0.263765   -0.119191   \n",
       "sentiment_score_at_max_complaint          -0.024765   0.014220    0.512224   \n",
       "\n",
       "                                      min_rating  percent_positive  \\\n",
       "missing_price                          -0.084188         -0.066885   \n",
       "item_rank                              -0.284773         -0.093563   \n",
       "avg_rating                              0.797841          0.928199   \n",
       "min_rating                              1.000000          0.739617   \n",
       "percent_positive                        0.739617          1.000000   \n",
       "percent_negative                       -0.721084         -0.802110   \n",
       "avg_verified_reviewers                  0.050736          0.087400   \n",
       "min_date                               -0.075741          0.017633   \n",
       "max_date                                0.183490          0.051160   \n",
       "product_lifespan                        0.248919          0.026545   \n",
       "num_bots_per_asin                       0.056458          0.038190   \n",
       "unique_reviewer_count                   0.075076          0.011486   \n",
       "avg_reviews_per_day                     0.024598          0.025616   \n",
       "reviews_per_product                     0.073721          0.011370   \n",
       "avg_review_length_words                -0.073316         -0.105495   \n",
       "mean_sentiment_score                    0.551026          0.643896   \n",
       "mean_complaint_similarity              -0.207011         -0.255409   \n",
       "mean_shipping_similarity               -0.163593         -0.175981   \n",
       "max_complaint_similarity                0.082534         -0.165793   \n",
       "shipping_similarity_at_max_complaint    0.035150         -0.110991   \n",
       "sentiment_score_at_max_complaint        0.328040          0.477634   \n",
       "\n",
       "                                      percent_negative  \\\n",
       "missing_price                                 0.059782   \n",
       "item_rank                                     0.086678   \n",
       "avg_rating                                   -0.902056   \n",
       "min_rating                                   -0.721084   \n",
       "percent_positive                             -0.802110   \n",
       "percent_negative                              1.000000   \n",
       "avg_verified_reviewers                       -0.084272   \n",
       "min_date                                      0.004132   \n",
       "max_date                                     -0.029223   \n",
       "product_lifespan                             -0.030873   \n",
       "num_bots_per_asin                            -0.034799   \n",
       "unique_reviewer_count                        -0.011292   \n",
       "avg_reviews_per_day                          -0.022650   \n",
       "reviews_per_product                          -0.011240   \n",
       "avg_review_length_words                       0.066051   \n",
       "mean_sentiment_score                         -0.646173   \n",
       "mean_complaint_similarity                     0.256231   \n",
       "mean_shipping_similarity                      0.196444   \n",
       "max_complaint_similarity                      0.167256   \n",
       "shipping_similarity_at_max_complaint          0.127280   \n",
       "sentiment_score_at_max_complaint             -0.483966   \n",
       "\n",
       "                                      avg_verified_reviewers  min_date  \\\n",
       "missing_price                                      -0.080962 -0.094594   \n",
       "item_rank                                          -0.151444 -0.142030   \n",
       "avg_rating                                          0.103396  0.029055   \n",
       "min_rating                                          0.050736 -0.075741   \n",
       "percent_positive                                    0.087400  0.017633   \n",
       "percent_negative                                   -0.084272  0.004132   \n",
       "avg_verified_reviewers                              1.000000  0.329849   \n",
       "min_date                                            0.329849  1.000000   \n",
       "max_date                                            0.287963  0.519009   \n",
       "product_lifespan                                   -0.105624 -0.638843   \n",
       "num_bots_per_asin                                   0.013744 -0.057167   \n",
       "unique_reviewer_count                               0.003472 -0.116391   \n",
       "avg_reviews_per_day                                 0.033327  0.007440   \n",
       "reviews_per_product                                 0.003216 -0.120776   \n",
       "avg_review_length_words                            -0.338600 -0.295380   \n",
       "mean_sentiment_score                                0.109111  0.077075   \n",
       "mean_complaint_similarity                          -0.056607 -0.035293   \n",
       "mean_shipping_similarity                            0.114678  0.128746   \n",
       "max_complaint_similarity                           -0.046647 -0.191535   \n",
       "shipping_similarity_at_max_complaint                0.080529 -0.020447   \n",
       "sentiment_score_at_max_complaint                    0.082968  0.088981   \n",
       "\n",
       "                                      max_date  product_lifespan  ...  \\\n",
       "missing_price                        -0.263965         -0.132964  ...   \n",
       "item_rank                            -0.609545         -0.391541  ...   \n",
       "avg_rating                            0.062871          0.024453  ...   \n",
       "min_rating                            0.183490          0.248919  ...   \n",
       "percent_positive                      0.051160          0.026545  ...   \n",
       "percent_negative                     -0.029223         -0.030873  ...   \n",
       "avg_verified_reviewers                0.287963         -0.105624  ...   \n",
       "min_date                              0.519009         -0.638843  ...   \n",
       "max_date                              1.000000          0.326040  ...   \n",
       "product_lifespan                      0.326040          1.000000  ...   \n",
       "num_bots_per_asin                     0.113362          0.165257  ...   \n",
       "unique_reviewer_count                 0.169746          0.281507  ...   \n",
       "avg_reviews_per_day                   0.041838          0.029428  ...   \n",
       "reviews_per_product                   0.166758          0.283666  ...   \n",
       "avg_review_length_words              -0.253813          0.098239  ...   \n",
       "mean_sentiment_score                  0.105516          0.009726  ...   \n",
       "mean_complaint_similarity            -0.043318          0.000044  ...   \n",
       "mean_shipping_similarity              0.075688         -0.074266  ...   \n",
       "max_complaint_similarity              0.273420          0.457925  ...   \n",
       "shipping_similarity_at_max_complaint  0.251189          0.248697  ...   \n",
       "sentiment_score_at_max_complaint      0.002470         -0.096188  ...   \n",
       "\n",
       "                                      unique_reviewer_count  \\\n",
       "missing_price                                     -0.076755   \n",
       "item_rank                                         -0.199884   \n",
       "avg_rating                                         0.011853   \n",
       "min_rating                                         0.075076   \n",
       "percent_positive                                   0.011486   \n",
       "percent_negative                                  -0.011292   \n",
       "avg_verified_reviewers                             0.003472   \n",
       "min_date                                          -0.116391   \n",
       "max_date                                           0.169746   \n",
       "product_lifespan                                   0.281507   \n",
       "num_bots_per_asin                                  0.448655   \n",
       "unique_reviewer_count                              1.000000   \n",
       "avg_reviews_per_day                                0.008240   \n",
       "reviews_per_product                                0.987056   \n",
       "avg_review_length_words                            0.003985   \n",
       "mean_sentiment_score                               0.016020   \n",
       "mean_complaint_similarity                          0.000255   \n",
       "mean_shipping_similarity                          -0.025254   \n",
       "max_complaint_similarity                           0.312837   \n",
       "shipping_similarity_at_max_complaint               0.158865   \n",
       "sentiment_score_at_max_complaint                  -0.072412   \n",
       "\n",
       "                                      avg_reviews_per_day  \\\n",
       "missing_price                                   -0.035336   \n",
       "item_rank                                       -0.044102   \n",
       "avg_rating                                       0.027177   \n",
       "min_rating                                       0.024598   \n",
       "percent_positive                                 0.025616   \n",
       "percent_negative                                -0.022650   \n",
       "avg_verified_reviewers                           0.033327   \n",
       "min_date                                         0.007440   \n",
       "max_date                                         0.041838   \n",
       "product_lifespan                                 0.029428   \n",
       "num_bots_per_asin                                0.171682   \n",
       "unique_reviewer_count                            0.008240   \n",
       "avg_reviews_per_day                              1.000000   \n",
       "reviews_per_product                              0.009486   \n",
       "avg_review_length_words                         -0.078165   \n",
       "mean_sentiment_score                             0.039792   \n",
       "mean_complaint_similarity                        0.002218   \n",
       "mean_shipping_similarity                         0.036032   \n",
       "max_complaint_similarity                         0.023296   \n",
       "shipping_similarity_at_max_complaint             0.044437   \n",
       "sentiment_score_at_max_complaint                 0.028822   \n",
       "\n",
       "                                      reviews_per_product  \\\n",
       "missing_price                                   -0.075929   \n",
       "item_rank                                       -0.196587   \n",
       "avg_rating                                       0.011709   \n",
       "min_rating                                       0.073721   \n",
       "percent_positive                                 0.011370   \n",
       "percent_negative                                -0.011240   \n",
       "avg_verified_reviewers                           0.003216   \n",
       "min_date                                        -0.120776   \n",
       "max_date                                         0.166758   \n",
       "product_lifespan                                 0.283666   \n",
       "num_bots_per_asin                                0.454697   \n",
       "unique_reviewer_count                            0.987056   \n",
       "avg_reviews_per_day                              0.009486   \n",
       "reviews_per_product                              1.000000   \n",
       "avg_review_length_words                          0.004637   \n",
       "mean_sentiment_score                             0.015652   \n",
       "mean_complaint_similarity                        0.000614   \n",
       "mean_shipping_similarity                        -0.025299   \n",
       "max_complaint_similarity                         0.309501   \n",
       "shipping_similarity_at_max_complaint             0.156456   \n",
       "sentiment_score_at_max_complaint                -0.071260   \n",
       "\n",
       "                                      avg_review_length_words  \\\n",
       "missing_price                                        0.081868   \n",
       "item_rank                                            0.136703   \n",
       "avg_rating                                          -0.116737   \n",
       "min_rating                                          -0.073316   \n",
       "percent_positive                                    -0.105495   \n",
       "percent_negative                                     0.066051   \n",
       "avg_verified_reviewers                              -0.338600   \n",
       "min_date                                            -0.295380   \n",
       "max_date                                            -0.253813   \n",
       "product_lifespan                                     0.098239   \n",
       "num_bots_per_asin                                   -0.026401   \n",
       "unique_reviewer_count                                0.003985   \n",
       "avg_reviews_per_day                                 -0.078165   \n",
       "reviews_per_product                                  0.004637   \n",
       "avg_review_length_words                              1.000000   \n",
       "mean_sentiment_score                                -0.154807   \n",
       "mean_complaint_similarity                            0.148146   \n",
       "mean_shipping_similarity                            -0.162734   \n",
       "max_complaint_similarity                             0.110687   \n",
       "shipping_similarity_at_max_complaint                -0.117527   \n",
       "sentiment_score_at_max_complaint                    -0.117818   \n",
       "\n",
       "                                      mean_sentiment_score  \\\n",
       "missing_price                                    -0.059014   \n",
       "item_rank                                        -0.109818   \n",
       "avg_rating                                        0.687027   \n",
       "min_rating                                        0.551026   \n",
       "percent_positive                                  0.643896   \n",
       "percent_negative                                 -0.646173   \n",
       "avg_verified_reviewers                            0.109111   \n",
       "min_date                                          0.077075   \n",
       "max_date                                          0.105516   \n",
       "product_lifespan                                  0.009726   \n",
       "num_bots_per_asin                                 0.035951   \n",
       "unique_reviewer_count                             0.016020   \n",
       "avg_reviews_per_day                               0.039792   \n",
       "reviews_per_product                               0.015652   \n",
       "avg_review_length_words                          -0.154807   \n",
       "mean_sentiment_score                              1.000000   \n",
       "mean_complaint_similarity                        -0.221099   \n",
       "mean_shipping_similarity                         -0.118711   \n",
       "max_complaint_similarity                         -0.132738   \n",
       "shipping_similarity_at_max_complaint             -0.067076   \n",
       "sentiment_score_at_max_complaint                  0.722860   \n",
       "\n",
       "                                      mean_complaint_similarity  \\\n",
       "missing_price                                          0.023654   \n",
       "item_rank                                              0.055039   \n",
       "avg_rating                                            -0.274461   \n",
       "min_rating                                            -0.207011   \n",
       "percent_positive                                      -0.255409   \n",
       "percent_negative                                       0.256231   \n",
       "avg_verified_reviewers                                -0.056607   \n",
       "min_date                                              -0.035293   \n",
       "max_date                                              -0.043318   \n",
       "product_lifespan                                       0.000044   \n",
       "num_bots_per_asin                                     -0.004584   \n",
       "unique_reviewer_count                                  0.000255   \n",
       "avg_reviews_per_day                                    0.002218   \n",
       "reviews_per_product                                    0.000614   \n",
       "avg_review_length_words                                0.148146   \n",
       "mean_sentiment_score                                  -0.221099   \n",
       "mean_complaint_similarity                              1.000000   \n",
       "mean_shipping_similarity                               0.596156   \n",
       "max_complaint_similarity                               0.652085   \n",
       "shipping_similarity_at_max_complaint                   0.401017   \n",
       "sentiment_score_at_max_complaint                      -0.186382   \n",
       "\n",
       "                                      mean_shipping_similarity  \\\n",
       "missing_price                                        -0.009715   \n",
       "item_rank                                             0.004621   \n",
       "avg_rating                                           -0.187014   \n",
       "min_rating                                           -0.163593   \n",
       "percent_positive                                     -0.175981   \n",
       "percent_negative                                      0.196444   \n",
       "avg_verified_reviewers                                0.114678   \n",
       "min_date                                              0.128746   \n",
       "max_date                                              0.075688   \n",
       "product_lifespan                                     -0.074266   \n",
       "num_bots_per_asin                                     0.006389   \n",
       "unique_reviewer_count                                -0.025254   \n",
       "avg_reviews_per_day                                   0.036032   \n",
       "reviews_per_product                                  -0.025299   \n",
       "avg_review_length_words                              -0.162734   \n",
       "mean_sentiment_score                                 -0.118711   \n",
       "mean_complaint_similarity                             0.596156   \n",
       "mean_shipping_similarity                              1.000000   \n",
       "max_complaint_similarity                              0.357910   \n",
       "shipping_similarity_at_max_complaint                  0.686648   \n",
       "sentiment_score_at_max_complaint                     -0.095049   \n",
       "\n",
       "                                      max_complaint_similarity  \\\n",
       "missing_price                                        -0.086209   \n",
       "item_rank                                            -0.361435   \n",
       "avg_rating                                           -0.179334   \n",
       "min_rating                                            0.082534   \n",
       "percent_positive                                     -0.165793   \n",
       "percent_negative                                      0.167256   \n",
       "avg_verified_reviewers                               -0.046647   \n",
       "min_date                                             -0.191535   \n",
       "max_date                                              0.273420   \n",
       "product_lifespan                                      0.457925   \n",
       "num_bots_per_asin                                     0.184230   \n",
       "unique_reviewer_count                                 0.312837   \n",
       "avg_reviews_per_day                                   0.023296   \n",
       "reviews_per_product                                   0.309501   \n",
       "avg_review_length_words                               0.110687   \n",
       "mean_sentiment_score                                 -0.132738   \n",
       "mean_complaint_similarity                             0.652085   \n",
       "mean_shipping_similarity                              0.357910   \n",
       "max_complaint_similarity                              1.000000   \n",
       "shipping_similarity_at_max_complaint                  0.606034   \n",
       "sentiment_score_at_max_complaint                     -0.254983   \n",
       "\n",
       "                                      shipping_similarity_at_max_complaint  \\\n",
       "missing_price                                                    -0.078643   \n",
       "item_rank                                                        -0.263765   \n",
       "avg_rating                                                       -0.119191   \n",
       "min_rating                                                        0.035150   \n",
       "percent_positive                                                 -0.110991   \n",
       "percent_negative                                                  0.127280   \n",
       "avg_verified_reviewers                                            0.080529   \n",
       "min_date                                                         -0.020447   \n",
       "max_date                                                          0.251189   \n",
       "product_lifespan                                                  0.248697   \n",
       "num_bots_per_asin                                                 0.131375   \n",
       "unique_reviewer_count                                             0.158865   \n",
       "avg_reviews_per_day                                               0.044437   \n",
       "reviews_per_product                                               0.156456   \n",
       "avg_review_length_words                                          -0.117527   \n",
       "mean_sentiment_score                                             -0.067076   \n",
       "mean_complaint_similarity                                         0.401017   \n",
       "mean_shipping_similarity                                          0.686648   \n",
       "max_complaint_similarity                                          0.606034   \n",
       "shipping_similarity_at_max_complaint                              1.000000   \n",
       "sentiment_score_at_max_complaint                                 -0.145711   \n",
       "\n",
       "                                      sentiment_score_at_max_complaint  \n",
       "missing_price                                                -0.024765  \n",
       "item_rank                                                     0.014220  \n",
       "avg_rating                                                    0.512224  \n",
       "min_rating                                                    0.328040  \n",
       "percent_positive                                              0.477634  \n",
       "percent_negative                                             -0.483966  \n",
       "avg_verified_reviewers                                        0.082968  \n",
       "min_date                                                      0.088981  \n",
       "max_date                                                      0.002470  \n",
       "product_lifespan                                             -0.096188  \n",
       "num_bots_per_asin                                            -0.015611  \n",
       "unique_reviewer_count                                        -0.072412  \n",
       "avg_reviews_per_day                                           0.028822  \n",
       "reviews_per_product                                          -0.071260  \n",
       "avg_review_length_words                                      -0.117818  \n",
       "mean_sentiment_score                                          0.722860  \n",
       "mean_complaint_similarity                                    -0.186382  \n",
       "mean_shipping_similarity                                     -0.095049  \n",
       "max_complaint_similarity                                     -0.254983  \n",
       "shipping_similarity_at_max_complaint                         -0.145711  \n",
       "sentiment_score_at_max_complaint                              1.000000  \n",
       "\n",
       "[21 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation matrix for non-embedding features\n",
    "train_df[begin_features[1:]+end_features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdbc4526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>reviews_per_product</td>\n",
       "      <td>unique_reviewer_count</td>\n",
       "      <td>0.987056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>percent_positive</td>\n",
       "      <td>avg_rating</td>\n",
       "      <td>0.928199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>min_rating</td>\n",
       "      <td>avg_rating</td>\n",
       "      <td>0.797841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>summary_embedding_97</td>\n",
       "      <td>summary_embedding_46</td>\n",
       "      <td>0.751040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>percent_positive</td>\n",
       "      <td>min_rating</td>\n",
       "      <td>0.739617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55045</th>\n",
       "      <td>summary_embedding_317</td>\n",
       "      <td>summary_embedding_84</td>\n",
       "      <td>0.500751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9640</th>\n",
       "      <td>summary_embedding_124</td>\n",
       "      <td>summary_embedding_34</td>\n",
       "      <td>0.500694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68949</th>\n",
       "      <td>summary_embedding_356</td>\n",
       "      <td>summary_embedding_299</td>\n",
       "      <td>0.500498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67010</th>\n",
       "      <td>summary_embedding_351</td>\n",
       "      <td>summary_embedding_200</td>\n",
       "      <td>0.500167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24051</th>\n",
       "      <td>summary_embedding_204</td>\n",
       "      <td>summary_embedding_165</td>\n",
       "      <td>0.500108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature_1              Feature_2  Correlation\n",
       "89       reviews_per_product  unique_reviewer_count     0.987056\n",
       "8           percent_positive             avg_rating     0.928199\n",
       "5                 min_rating             avg_rating     0.797841\n",
       "6277    summary_embedding_97   summary_embedding_46     0.751040\n",
       "9           percent_positive             min_rating     0.739617\n",
       "...                      ...                    ...          ...\n",
       "55045  summary_embedding_317   summary_embedding_84     0.500751\n",
       "9640   summary_embedding_124   summary_embedding_34     0.500694\n",
       "68949  summary_embedding_356  summary_embedding_299     0.500498\n",
       "67010  summary_embedding_351  summary_embedding_200     0.500167\n",
       "24051  summary_embedding_204  summary_embedding_165     0.500108\n",
       "\n",
       "[452 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the correlation matrix to see which features have higher than |0.5| correlation\n",
    "feature_corr_matrix = train_df[train_df.columns[1:]].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(feature_corr_matrix, dtype=bool))\n",
    "\n",
    "high_corr = feature_corr_matrix.where(~mask).stack().reset_index()\n",
    "high_corr.columns = ['Feature_1', 'Feature_2', 'Correlation']\n",
    "\n",
    "pos_corr_result = (high_corr[high_corr['Correlation'] >= 0.5])\n",
    "\n",
    "pos_corr_result = pos_corr_result.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# Show Results of the filter\n",
    "pos_corr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d1f8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>reviews_per_product</td>\n",
       "      <td>unique_reviewer_count</td>\n",
       "      <td>0.987056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>percent_positive</td>\n",
       "      <td>avg_rating</td>\n",
       "      <td>0.928199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>min_rating</td>\n",
       "      <td>avg_rating</td>\n",
       "      <td>0.797841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>summary_embedding_97</td>\n",
       "      <td>summary_embedding_46</td>\n",
       "      <td>0.751040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>percent_positive</td>\n",
       "      <td>min_rating</td>\n",
       "      <td>0.739617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310861</th>\n",
       "      <td>sentiment_score_at_max_complaint</td>\n",
       "      <td>mean_sentiment_score</td>\n",
       "      <td>0.722860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>summary_embedding_97</td>\n",
       "      <td>summary_embedding_34</td>\n",
       "      <td>0.713441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>summary_embedding_46</td>\n",
       "      <td>summary_embedding_34</td>\n",
       "      <td>0.702397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42307</th>\n",
       "      <td>summary_embedding_276</td>\n",
       "      <td>summary_embedding_97</td>\n",
       "      <td>0.697054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306155</th>\n",
       "      <td>mean_sentiment_score</td>\n",
       "      <td>avg_rating</td>\n",
       "      <td>0.687027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Feature_1              Feature_2  Correlation\n",
       "89                   reviews_per_product  unique_reviewer_count     0.987056\n",
       "8                       percent_positive             avg_rating     0.928199\n",
       "5                             min_rating             avg_rating     0.797841\n",
       "6277                summary_embedding_97   summary_embedding_46     0.751040\n",
       "9                       percent_positive             min_rating     0.739617\n",
       "310861  sentiment_score_at_max_complaint   mean_sentiment_score     0.722860\n",
       "6265                summary_embedding_97   summary_embedding_34     0.713441\n",
       "1879                summary_embedding_46   summary_embedding_34     0.702397\n",
       "42307              summary_embedding_276   summary_embedding_97     0.697054\n",
       "306155              mean_sentiment_score             avg_rating     0.687027"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 positively correlated features\n",
    "# need to drop reviews_per_product or num_of_rating\n",
    "pos_corr_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e0bea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>percent_negative</td>\n",
       "      <td>avg_rating</td>\n",
       "      <td>-0.902056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193657</th>\n",
       "      <td>reviewtext_embedding_223</td>\n",
       "      <td>reviewtext_embedding_127</td>\n",
       "      <td>-0.897805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28345</th>\n",
       "      <td>summary_embedding_223</td>\n",
       "      <td>summary_embedding_127</td>\n",
       "      <td>-0.839951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>percent_negative</td>\n",
       "      <td>percent_positive</td>\n",
       "      <td>-0.802110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>percent_negative</td>\n",
       "      <td>min_rating</td>\n",
       "      <td>-0.721084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52697</th>\n",
       "      <td>summary_embedding_310</td>\n",
       "      <td>summary_embedding_32</td>\n",
       "      <td>-0.500465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62663</th>\n",
       "      <td>summary_embedding_339</td>\n",
       "      <td>summary_embedding_167</td>\n",
       "      <td>-0.500393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>summary_embedding_32</td>\n",
       "      <td>summary_embedding_3</td>\n",
       "      <td>-0.500260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42383</th>\n",
       "      <td>summary_embedding_276</td>\n",
       "      <td>summary_embedding_173</td>\n",
       "      <td>-0.500213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61310</th>\n",
       "      <td>summary_embedding_335</td>\n",
       "      <td>summary_embedding_220</td>\n",
       "      <td>-0.500123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature_1                 Feature_2  Correlation\n",
       "12              percent_negative                avg_rating    -0.902056\n",
       "193657  reviewtext_embedding_223  reviewtext_embedding_127    -0.897805\n",
       "28345      summary_embedding_223     summary_embedding_127    -0.839951\n",
       "14              percent_negative          percent_positive    -0.802110\n",
       "13              percent_negative                min_rating    -0.721084\n",
       "...                          ...                       ...          ...\n",
       "52697      summary_embedding_310      summary_embedding_32    -0.500465\n",
       "62663      summary_embedding_339     summary_embedding_167    -0.500393\n",
       "1099        summary_embedding_32       summary_embedding_3    -0.500260\n",
       "42383      summary_embedding_276     summary_embedding_173    -0.500213\n",
       "61310      summary_embedding_335     summary_embedding_220    -0.500123\n",
       "\n",
       "[454 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative correlation between features\n",
    "neg_corr_result = (high_corr[high_corr['Correlation'] <= -0.5])\n",
    "\n",
    "neg_corr_result = neg_corr_result.sort_values(by='Correlation', ascending=True)\n",
    "\n",
    "# Show Results of the filter\n",
    "neg_corr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42521bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>percent_negative</td>\n",
       "      <td>avg_rating</td>\n",
       "      <td>-0.902056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193657</th>\n",
       "      <td>reviewtext_embedding_223</td>\n",
       "      <td>reviewtext_embedding_127</td>\n",
       "      <td>-0.897805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28345</th>\n",
       "      <td>summary_embedding_223</td>\n",
       "      <td>summary_embedding_127</td>\n",
       "      <td>-0.839951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>percent_negative</td>\n",
       "      <td>percent_positive</td>\n",
       "      <td>-0.802110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>percent_negative</td>\n",
       "      <td>min_rating</td>\n",
       "      <td>-0.721084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69812</th>\n",
       "      <td>summary_embedding_359</td>\n",
       "      <td>summary_embedding_46</td>\n",
       "      <td>-0.706595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52711</th>\n",
       "      <td>summary_embedding_310</td>\n",
       "      <td>summary_embedding_46</td>\n",
       "      <td>-0.704846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52762</th>\n",
       "      <td>summary_embedding_310</td>\n",
       "      <td>summary_embedding_97</td>\n",
       "      <td>-0.701160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257417</th>\n",
       "      <td>reviewtext_embedding_319</td>\n",
       "      <td>avg_review_length_words</td>\n",
       "      <td>-0.699696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58765</th>\n",
       "      <td>summary_embedding_328</td>\n",
       "      <td>summary_embedding_97</td>\n",
       "      <td>-0.690493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature_1                 Feature_2  Correlation\n",
       "12              percent_negative                avg_rating    -0.902056\n",
       "193657  reviewtext_embedding_223  reviewtext_embedding_127    -0.897805\n",
       "28345      summary_embedding_223     summary_embedding_127    -0.839951\n",
       "14              percent_negative          percent_positive    -0.802110\n",
       "13              percent_negative                min_rating    -0.721084\n",
       "69812      summary_embedding_359      summary_embedding_46    -0.706595\n",
       "52711      summary_embedding_310      summary_embedding_46    -0.704846\n",
       "52762      summary_embedding_310      summary_embedding_97    -0.701160\n",
       "257417  reviewtext_embedding_319   avg_review_length_words    -0.699696\n",
       "58765      summary_embedding_328      summary_embedding_97    -0.690493"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 negatively correlated features\n",
    "neg_corr_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8446b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (train_df, val_df):\n",
    "    df.drop(['percent_positive', 'percent_negative', 'unique_reviewer_count'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee1c870",
   "metadata": {},
   "source": [
    "Pre-Processing and PCA on Embedding Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101771e",
   "metadata": {},
   "source": [
    "Make a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('logreg', LogisticRegression(penalty=None, class_weight='balanced'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73a819e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebekaheichberg/anaconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;item_rank&#x27;, &#x27;avg_rating&#x27;,\n",
       "                                                   &#x27;min_rating&#x27;,\n",
       "                                                   &#x27;percent_positive&#x27;,\n",
       "                                                   &#x27;percent_negative&#x27;,\n",
       "                                                   &#x27;avg_verified_reviewers&#x27;,\n",
       "                                                   &#x27;product_lifespan&#x27;,\n",
       "                                                   &#x27;num_bots_per_asin&#x27;,\n",
       "                                                   &#x27;unique_reviewer_count&#x27;,\n",
       "                                                   &#x27;avg_reviews_per_day&#x27;,\n",
       "                                                   &#x27;reviews_per_product&#x27;,\n",
       "                                                   &#x27;avg_review_length_words&#x27;,\n",
       "                                                   &#x27;summary_embedding_0&#x27;,\n",
       "                                                   &#x27;sum...\n",
       "                                                   &#x27;summary_embedding_8&#x27;,\n",
       "                                                   &#x27;summary_embedding_9&#x27;,\n",
       "                                                   &#x27;summary_embedding_10&#x27;,\n",
       "                                                   &#x27;summary_embedding_11&#x27;,\n",
       "                                                   &#x27;summary_embedding_12&#x27;,\n",
       "                                                   &#x27;summary_embedding_13&#x27;,\n",
       "                                                   &#x27;summary_embedding_14&#x27;,\n",
       "                                                   &#x27;summary_embedding_15&#x27;,\n",
       "                                                   &#x27;summary_embedding_16&#x27;,\n",
       "                                                   &#x27;summary_embedding_17&#x27;, ...]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;category&#x27;])])),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;item_rank&#x27;, &#x27;avg_rating&#x27;,\n",
       "                                                   &#x27;min_rating&#x27;,\n",
       "                                                   &#x27;percent_positive&#x27;,\n",
       "                                                   &#x27;percent_negative&#x27;,\n",
       "                                                   &#x27;avg_verified_reviewers&#x27;,\n",
       "                                                   &#x27;product_lifespan&#x27;,\n",
       "                                                   &#x27;num_bots_per_asin&#x27;,\n",
       "                                                   &#x27;unique_reviewer_count&#x27;,\n",
       "                                                   &#x27;avg_reviews_per_day&#x27;,\n",
       "                                                   &#x27;reviews_per_product&#x27;,\n",
       "                                                   &#x27;avg_review_length_words&#x27;,\n",
       "                                                   &#x27;summary_embedding_0&#x27;,\n",
       "                                                   &#x27;sum...\n",
       "                                                   &#x27;summary_embedding_8&#x27;,\n",
       "                                                   &#x27;summary_embedding_9&#x27;,\n",
       "                                                   &#x27;summary_embedding_10&#x27;,\n",
       "                                                   &#x27;summary_embedding_11&#x27;,\n",
       "                                                   &#x27;summary_embedding_12&#x27;,\n",
       "                                                   &#x27;summary_embedding_13&#x27;,\n",
       "                                                   &#x27;summary_embedding_14&#x27;,\n",
       "                                                   &#x27;summary_embedding_15&#x27;,\n",
       "                                                   &#x27;summary_embedding_16&#x27;,\n",
       "                                                   &#x27;summary_embedding_17&#x27;, ...]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;category&#x27;])])),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=None))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessing: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessing: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;item_rank&#x27;, &#x27;avg_rating&#x27;, &#x27;min_rating&#x27;,\n",
       "                                  &#x27;percent_positive&#x27;, &#x27;percent_negative&#x27;,\n",
       "                                  &#x27;avg_verified_reviewers&#x27;, &#x27;product_lifespan&#x27;,\n",
       "                                  &#x27;num_bots_per_asin&#x27;, &#x27;unique_reviewer_count&#x27;,\n",
       "                                  &#x27;avg_reviews_per_day&#x27;, &#x27;reviews_per_product&#x27;,\n",
       "                                  &#x27;avg_review_length_words&#x27;,\n",
       "                                  &#x27;summary_embedding_0&#x27;, &#x27;summary_embedding_1&#x27;,\n",
       "                                  &#x27;summary_embedd...\n",
       "                                  &#x27;summary_embedding_4&#x27;, &#x27;summary_embedding_5&#x27;,\n",
       "                                  &#x27;summary_embedding_6&#x27;, &#x27;summary_embedding_7&#x27;,\n",
       "                                  &#x27;summary_embedding_8&#x27;, &#x27;summary_embedding_9&#x27;,\n",
       "                                  &#x27;summary_embedding_10&#x27;,\n",
       "                                  &#x27;summary_embedding_11&#x27;,\n",
       "                                  &#x27;summary_embedding_12&#x27;,\n",
       "                                  &#x27;summary_embedding_13&#x27;,\n",
       "                                  &#x27;summary_embedding_14&#x27;,\n",
       "                                  &#x27;summary_embedding_15&#x27;,\n",
       "                                  &#x27;summary_embedding_16&#x27;,\n",
       "                                  &#x27;summary_embedding_17&#x27;, ...]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;category&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;item_rank&#x27;, &#x27;avg_rating&#x27;, &#x27;min_rating&#x27;, &#x27;percent_positive&#x27;, &#x27;percent_negative&#x27;, &#x27;avg_verified_reviewers&#x27;, &#x27;product_lifespan&#x27;, &#x27;num_bots_per_asin&#x27;, &#x27;unique_reviewer_count&#x27;, &#x27;avg_reviews_per_day&#x27;, &#x27;reviews_per_product&#x27;, &#x27;avg_review_length_words&#x27;, &#x27;summary_embedding_0&#x27;, &#x27;summary_embedding_1&#x27;, &#x27;summary_embedding_2&#x27;, &#x27;summary_embedding_3&#x27;, &#x27;summary_embedding_4&#x27;, &#x27;summary_embedding_5&#x27;, &#x27;summary_embedding_6&#x27;, &#x27;summary_embedding_7&#x27;, &#x27;summary_embedding_8&#x27;, &#x27;summary_embedding_9&#x27;, &#x27;summary_embedding_10&#x27;, &#x27;summary_embedding_11&#x27;, &#x27;summary_embedding_12&#x27;, &#x27;summary_embedding_13&#x27;, &#x27;summary_embedding_14&#x27;, &#x27;summary_embedding_15&#x27;, &#x27;summary_embedding_16&#x27;, &#x27;summary_embedding_17&#x27;, &#x27;summary_embedding_18&#x27;, &#x27;summary_embedding_19&#x27;, &#x27;summary_embedding_20&#x27;, &#x27;summary_embedding_21&#x27;, &#x27;summary_embedding_22&#x27;, &#x27;summary_embedding_23&#x27;, &#x27;summary_embedding_24&#x27;, &#x27;summary_embedding_25&#x27;, &#x27;summary_embedding_26&#x27;, &#x27;summary_embedding_27&#x27;, &#x27;summary_embedding_28&#x27;, &#x27;summary_embedding_29&#x27;, &#x27;summary_embedding_30&#x27;, &#x27;summary_embedding_31&#x27;, &#x27;summary_embedding_32&#x27;, &#x27;summary_embedding_33&#x27;, &#x27;summary_embedding_34&#x27;, &#x27;summary_embedding_35&#x27;, &#x27;summary_embedding_36&#x27;, &#x27;summary_embedding_37&#x27;, &#x27;summary_embedding_38&#x27;, &#x27;summary_embedding_39&#x27;, &#x27;summary_embedding_40&#x27;, &#x27;summary_embedding_41&#x27;, &#x27;summary_embedding_42&#x27;, &#x27;summary_embedding_43&#x27;, &#x27;summary_embedding_44&#x27;, &#x27;summary_embedding_45&#x27;, &#x27;summary_embedding_46&#x27;, &#x27;summary_embedding_47&#x27;, &#x27;summary_embedding_48&#x27;, &#x27;summary_embedding_49&#x27;, &#x27;summary_embedding_50&#x27;, &#x27;summary_embedding_51&#x27;, &#x27;summary_embedding_52&#x27;, &#x27;summary_embedding_53&#x27;, &#x27;summary_embedding_54&#x27;, &#x27;summary_embedding_55&#x27;, &#x27;summary_embedding_56&#x27;, &#x27;summary_embedding_57&#x27;, &#x27;summary_embedding_58&#x27;, &#x27;summary_embedding_59&#x27;, &#x27;summary_embedding_60&#x27;, &#x27;summary_embedding_61&#x27;, &#x27;summary_embedding_62&#x27;, &#x27;summary_embedding_63&#x27;, &#x27;summary_embedding_64&#x27;, &#x27;summary_embedding_65&#x27;, &#x27;summary_embedding_66&#x27;, &#x27;summary_embedding_67&#x27;, &#x27;summary_embedding_68&#x27;, &#x27;summary_embedding_69&#x27;, &#x27;summary_embedding_70&#x27;, &#x27;summary_embedding_71&#x27;, &#x27;summary_embedding_72&#x27;, &#x27;summary_embedding_73&#x27;, &#x27;summary_embedding_74&#x27;, &#x27;summary_embedding_75&#x27;, &#x27;summary_embedding_76&#x27;, &#x27;summary_embedding_77&#x27;, &#x27;summary_embedding_78&#x27;, &#x27;summary_embedding_79&#x27;, &#x27;summary_embedding_80&#x27;, &#x27;summary_embedding_81&#x27;, &#x27;summary_embedding_82&#x27;, &#x27;summary_embedding_83&#x27;, &#x27;summary_embedding_84&#x27;, &#x27;summary_embedding_85&#x27;, &#x27;summary_embedding_86&#x27;, &#x27;summary_embedding_87&#x27;, &#x27;summary_embedding_88&#x27;, &#x27;summary_embedding_89&#x27;, &#x27;summary_embedding_90&#x27;, &#x27;summary_embedding_91&#x27;, &#x27;summary_embedding_92&#x27;, &#x27;summary_embedding_93&#x27;, &#x27;summary_embedding_94&#x27;, &#x27;summary_embedding_95&#x27;, &#x27;summary_embedding_96&#x27;, &#x27;summary_embedding_97&#x27;, &#x27;summary_embedding_98&#x27;, &#x27;summary_embedding_99&#x27;, &#x27;summary_embedding_100&#x27;, &#x27;summary_embedding_101&#x27;, &#x27;summary_embedding_102&#x27;, &#x27;summary_embedding_103&#x27;, &#x27;summary_embedding_104&#x27;, &#x27;summary_embedding_105&#x27;, &#x27;summary_embedding_106&#x27;, &#x27;summary_embedding_107&#x27;, &#x27;summary_embedding_108&#x27;, &#x27;summary_embedding_109&#x27;, &#x27;summary_embedding_110&#x27;, &#x27;summary_embedding_111&#x27;, &#x27;summary_embedding_112&#x27;, &#x27;summary_embedding_113&#x27;, &#x27;summary_embedding_114&#x27;, &#x27;summary_embedding_115&#x27;, &#x27;summary_embedding_116&#x27;, &#x27;summary_embedding_117&#x27;, &#x27;summary_embedding_118&#x27;, &#x27;summary_embedding_119&#x27;, &#x27;summary_embedding_120&#x27;, &#x27;summary_embedding_121&#x27;, &#x27;summary_embedding_122&#x27;, &#x27;summary_embedding_123&#x27;, &#x27;summary_embedding_124&#x27;, &#x27;summary_embedding_125&#x27;, &#x27;summary_embedding_126&#x27;, &#x27;summary_embedding_127&#x27;, &#x27;summary_embedding_128&#x27;, &#x27;summary_embedding_129&#x27;, &#x27;summary_embedding_130&#x27;, &#x27;summary_embedding_131&#x27;, &#x27;summary_embedding_132&#x27;, &#x27;summary_embedding_133&#x27;, &#x27;summary_embedding_134&#x27;, &#x27;summary_embedding_135&#x27;, &#x27;summary_embedding_136&#x27;, &#x27;summary_embedding_137&#x27;, &#x27;summary_embedding_138&#x27;, &#x27;summary_embedding_139&#x27;, &#x27;summary_embedding_140&#x27;, &#x27;summary_embedding_141&#x27;, &#x27;summary_embedding_142&#x27;, &#x27;summary_embedding_143&#x27;, &#x27;summary_embedding_144&#x27;, &#x27;summary_embedding_145&#x27;, &#x27;summary_embedding_146&#x27;, &#x27;summary_embedding_147&#x27;, &#x27;summary_embedding_148&#x27;, &#x27;summary_embedding_149&#x27;, &#x27;summary_embedding_150&#x27;, &#x27;summary_embedding_151&#x27;, &#x27;summary_embedding_152&#x27;, &#x27;summary_embedding_153&#x27;, &#x27;summary_embedding_154&#x27;, &#x27;summary_embedding_155&#x27;, &#x27;summary_embedding_156&#x27;, &#x27;summary_embedding_157&#x27;, &#x27;summary_embedding_158&#x27;, &#x27;summary_embedding_159&#x27;, &#x27;summary_embedding_160&#x27;, &#x27;summary_embedding_161&#x27;, &#x27;summary_embedding_162&#x27;, &#x27;summary_embedding_163&#x27;, &#x27;summary_embedding_164&#x27;, &#x27;summary_embedding_165&#x27;, &#x27;summary_embedding_166&#x27;, &#x27;summary_embedding_167&#x27;, &#x27;summary_embedding_168&#x27;, &#x27;summary_embedding_169&#x27;, &#x27;summary_embedding_170&#x27;, &#x27;summary_embedding_171&#x27;, &#x27;summary_embedding_172&#x27;, &#x27;summary_embedding_173&#x27;, &#x27;summary_embedding_174&#x27;, &#x27;summary_embedding_175&#x27;, &#x27;summary_embedding_176&#x27;, &#x27;summary_embedding_177&#x27;, &#x27;summary_embedding_178&#x27;, &#x27;summary_embedding_179&#x27;, &#x27;summary_embedding_180&#x27;, &#x27;summary_embedding_181&#x27;, &#x27;summary_embedding_182&#x27;, &#x27;summary_embedding_183&#x27;, &#x27;summary_embedding_184&#x27;, &#x27;summary_embedding_185&#x27;, &#x27;summary_embedding_186&#x27;, &#x27;summary_embedding_187&#x27;, &#x27;summary_embedding_188&#x27;, &#x27;summary_embedding_189&#x27;, &#x27;summary_embedding_190&#x27;, &#x27;summary_embedding_191&#x27;, &#x27;summary_embedding_192&#x27;, &#x27;summary_embedding_193&#x27;, &#x27;summary_embedding_194&#x27;, &#x27;summary_embedding_195&#x27;, &#x27;summary_embedding_196&#x27;, &#x27;summary_embedding_197&#x27;, &#x27;summary_embedding_198&#x27;, &#x27;summary_embedding_199&#x27;, &#x27;summary_embedding_200&#x27;, &#x27;summary_embedding_201&#x27;, &#x27;summary_embedding_202&#x27;, &#x27;summary_embedding_203&#x27;, &#x27;summary_embedding_204&#x27;, &#x27;summary_embedding_205&#x27;, &#x27;summary_embedding_206&#x27;, &#x27;summary_embedding_207&#x27;, &#x27;summary_embedding_208&#x27;, &#x27;summary_embedding_209&#x27;, &#x27;summary_embedding_210&#x27;, &#x27;summary_embedding_211&#x27;, &#x27;summary_embedding_212&#x27;, &#x27;summary_embedding_213&#x27;, &#x27;summary_embedding_214&#x27;, &#x27;summary_embedding_215&#x27;, &#x27;summary_embedding_216&#x27;, &#x27;summary_embedding_217&#x27;, &#x27;summary_embedding_218&#x27;, &#x27;summary_embedding_219&#x27;, &#x27;summary_embedding_220&#x27;, &#x27;summary_embedding_221&#x27;, &#x27;summary_embedding_222&#x27;, &#x27;summary_embedding_223&#x27;, &#x27;summary_embedding_224&#x27;, &#x27;summary_embedding_225&#x27;, &#x27;summary_embedding_226&#x27;, &#x27;summary_embedding_227&#x27;, &#x27;summary_embedding_228&#x27;, &#x27;summary_embedding_229&#x27;, &#x27;summary_embedding_230&#x27;, &#x27;summary_embedding_231&#x27;, &#x27;summary_embedding_232&#x27;, &#x27;summary_embedding_233&#x27;, &#x27;summary_embedding_234&#x27;, &#x27;summary_embedding_235&#x27;, &#x27;summary_embedding_236&#x27;, &#x27;summary_embedding_237&#x27;, &#x27;summary_embedding_238&#x27;, &#x27;summary_embedding_239&#x27;, &#x27;summary_embedding_240&#x27;, &#x27;summary_embedding_241&#x27;, &#x27;summary_embedding_242&#x27;, &#x27;summary_embedding_243&#x27;, &#x27;summary_embedding_244&#x27;, &#x27;summary_embedding_245&#x27;, &#x27;summary_embedding_246&#x27;, &#x27;summary_embedding_247&#x27;, &#x27;summary_embedding_248&#x27;, &#x27;summary_embedding_249&#x27;, &#x27;summary_embedding_250&#x27;, &#x27;summary_embedding_251&#x27;, &#x27;summary_embedding_252&#x27;, &#x27;summary_embedding_253&#x27;, &#x27;summary_embedding_254&#x27;, &#x27;summary_embedding_255&#x27;, &#x27;summary_embedding_256&#x27;, &#x27;summary_embedding_257&#x27;, &#x27;summary_embedding_258&#x27;, &#x27;summary_embedding_259&#x27;, &#x27;summary_embedding_260&#x27;, &#x27;summary_embedding_261&#x27;, &#x27;summary_embedding_262&#x27;, &#x27;summary_embedding_263&#x27;, &#x27;summary_embedding_264&#x27;, &#x27;summary_embedding_265&#x27;, &#x27;summary_embedding_266&#x27;, &#x27;summary_embedding_267&#x27;, &#x27;summary_embedding_268&#x27;, &#x27;summary_embedding_269&#x27;, &#x27;summary_embedding_270&#x27;, &#x27;summary_embedding_271&#x27;, &#x27;summary_embedding_272&#x27;, &#x27;summary_embedding_273&#x27;, &#x27;summary_embedding_274&#x27;, &#x27;summary_embedding_275&#x27;, &#x27;summary_embedding_276&#x27;, &#x27;summary_embedding_277&#x27;, &#x27;summary_embedding_278&#x27;, &#x27;summary_embedding_279&#x27;, &#x27;summary_embedding_280&#x27;, &#x27;summary_embedding_281&#x27;, &#x27;summary_embedding_282&#x27;, &#x27;summary_embedding_283&#x27;, &#x27;summary_embedding_284&#x27;, &#x27;summary_embedding_285&#x27;, &#x27;summary_embedding_286&#x27;, &#x27;summary_embedding_287&#x27;, &#x27;summary_embedding_288&#x27;, &#x27;summary_embedding_289&#x27;, &#x27;summary_embedding_290&#x27;, &#x27;summary_embedding_291&#x27;, &#x27;summary_embedding_292&#x27;, &#x27;summary_embedding_293&#x27;, &#x27;summary_embedding_294&#x27;, &#x27;summary_embedding_295&#x27;, &#x27;summary_embedding_296&#x27;, &#x27;summary_embedding_297&#x27;, &#x27;summary_embedding_298&#x27;, &#x27;summary_embedding_299&#x27;, &#x27;summary_embedding_300&#x27;, &#x27;summary_embedding_301&#x27;, &#x27;summary_embedding_302&#x27;, &#x27;summary_embedding_303&#x27;, &#x27;summary_embedding_304&#x27;, &#x27;summary_embedding_305&#x27;, &#x27;summary_embedding_306&#x27;, &#x27;summary_embedding_307&#x27;, &#x27;summary_embedding_308&#x27;, &#x27;summary_embedding_309&#x27;, &#x27;summary_embedding_310&#x27;, &#x27;summary_embedding_311&#x27;, &#x27;summary_embedding_312&#x27;, &#x27;summary_embedding_313&#x27;, &#x27;summary_embedding_314&#x27;, &#x27;summary_embedding_315&#x27;, &#x27;summary_embedding_316&#x27;, &#x27;summary_embedding_317&#x27;, &#x27;summary_embedding_318&#x27;, &#x27;summary_embedding_319&#x27;, &#x27;summary_embedding_320&#x27;, &#x27;summary_embedding_321&#x27;, &#x27;summary_embedding_322&#x27;, &#x27;summary_embedding_323&#x27;, &#x27;summary_embedding_324&#x27;, &#x27;summary_embedding_325&#x27;, &#x27;summary_embedding_326&#x27;, &#x27;summary_embedding_327&#x27;, &#x27;summary_embedding_328&#x27;, &#x27;summary_embedding_329&#x27;, &#x27;summary_embedding_330&#x27;, &#x27;summary_embedding_331&#x27;, &#x27;summary_embedding_332&#x27;, &#x27;summary_embedding_333&#x27;, &#x27;summary_embedding_334&#x27;, &#x27;summary_embedding_335&#x27;, &#x27;summary_embedding_336&#x27;, &#x27;summary_embedding_337&#x27;, &#x27;summary_embedding_338&#x27;, &#x27;summary_embedding_339&#x27;, &#x27;summary_embedding_340&#x27;, &#x27;summary_embedding_341&#x27;, &#x27;summary_embedding_342&#x27;, &#x27;summary_embedding_343&#x27;, &#x27;summary_embedding_344&#x27;, &#x27;summary_embedding_345&#x27;, &#x27;summary_embedding_346&#x27;, &#x27;summary_embedding_347&#x27;, &#x27;summary_embedding_348&#x27;, &#x27;summary_embedding_349&#x27;, &#x27;summary_embedding_350&#x27;, &#x27;summary_embedding_351&#x27;, &#x27;summary_embedding_352&#x27;, &#x27;summary_embedding_353&#x27;, &#x27;summary_embedding_354&#x27;, &#x27;summary_embedding_355&#x27;, &#x27;summary_embedding_356&#x27;, &#x27;summary_embedding_357&#x27;, &#x27;summary_embedding_358&#x27;, &#x27;summary_embedding_359&#x27;, &#x27;summary_embedding_360&#x27;, &#x27;summary_embedding_361&#x27;, &#x27;summary_embedding_362&#x27;, &#x27;summary_embedding_363&#x27;, &#x27;summary_embedding_364&#x27;, &#x27;summary_embedding_365&#x27;, &#x27;summary_embedding_366&#x27;, &#x27;summary_embedding_367&#x27;, &#x27;summary_embedding_368&#x27;, &#x27;summary_embedding_369&#x27;, &#x27;summary_embedding_370&#x27;, &#x27;summary_embedding_371&#x27;, &#x27;summary_embedding_372&#x27;, &#x27;summary_embedding_373&#x27;, &#x27;summary_embedding_374&#x27;, &#x27;summary_embedding_375&#x27;, &#x27;summary_embedding_376&#x27;, &#x27;summary_embedding_377&#x27;, &#x27;summary_embedding_378&#x27;, &#x27;summary_embedding_379&#x27;, &#x27;summary_embedding_380&#x27;, &#x27;summary_embedding_381&#x27;, &#x27;summary_embedding_382&#x27;, &#x27;summary_embedding_383&#x27;, &#x27;reviewtext_embedding_0&#x27;, &#x27;reviewtext_embedding_1&#x27;, &#x27;reviewtext_embedding_2&#x27;, &#x27;reviewtext_embedding_3&#x27;, &#x27;reviewtext_embedding_4&#x27;, &#x27;reviewtext_embedding_5&#x27;, &#x27;reviewtext_embedding_6&#x27;, &#x27;reviewtext_embedding_7&#x27;, &#x27;reviewtext_embedding_8&#x27;, &#x27;reviewtext_embedding_9&#x27;, &#x27;reviewtext_embedding_10&#x27;, &#x27;reviewtext_embedding_11&#x27;, &#x27;reviewtext_embedding_12&#x27;, &#x27;reviewtext_embedding_13&#x27;, &#x27;reviewtext_embedding_14&#x27;, &#x27;reviewtext_embedding_15&#x27;, &#x27;reviewtext_embedding_16&#x27;, &#x27;reviewtext_embedding_17&#x27;, &#x27;reviewtext_embedding_18&#x27;, &#x27;reviewtext_embedding_19&#x27;, &#x27;reviewtext_embedding_20&#x27;, &#x27;reviewtext_embedding_21&#x27;, &#x27;reviewtext_embedding_22&#x27;, &#x27;reviewtext_embedding_23&#x27;, &#x27;reviewtext_embedding_24&#x27;, &#x27;reviewtext_embedding_25&#x27;, &#x27;reviewtext_embedding_26&#x27;, &#x27;reviewtext_embedding_27&#x27;, &#x27;reviewtext_embedding_28&#x27;, &#x27;reviewtext_embedding_29&#x27;, &#x27;reviewtext_embedding_30&#x27;, &#x27;reviewtext_embedding_31&#x27;, &#x27;reviewtext_embedding_32&#x27;, &#x27;reviewtext_embedding_33&#x27;, &#x27;reviewtext_embedding_34&#x27;, &#x27;reviewtext_embedding_35&#x27;, &#x27;reviewtext_embedding_36&#x27;, &#x27;reviewtext_embedding_37&#x27;, &#x27;reviewtext_embedding_38&#x27;, &#x27;reviewtext_embedding_39&#x27;, &#x27;reviewtext_embedding_40&#x27;, &#x27;reviewtext_embedding_41&#x27;, &#x27;reviewtext_embedding_42&#x27;, &#x27;reviewtext_embedding_43&#x27;, &#x27;reviewtext_embedding_44&#x27;, &#x27;reviewtext_embedding_45&#x27;, &#x27;reviewtext_embedding_46&#x27;, &#x27;reviewtext_embedding_47&#x27;, &#x27;reviewtext_embedding_48&#x27;, &#x27;reviewtext_embedding_49&#x27;, &#x27;reviewtext_embedding_50&#x27;, &#x27;reviewtext_embedding_51&#x27;, &#x27;reviewtext_embedding_52&#x27;, &#x27;reviewtext_embedding_53&#x27;, &#x27;reviewtext_embedding_54&#x27;, &#x27;reviewtext_embedding_55&#x27;, &#x27;reviewtext_embedding_56&#x27;, &#x27;reviewtext_embedding_57&#x27;, &#x27;reviewtext_embedding_58&#x27;, &#x27;reviewtext_embedding_59&#x27;, &#x27;reviewtext_embedding_60&#x27;, &#x27;reviewtext_embedding_61&#x27;, &#x27;reviewtext_embedding_62&#x27;, &#x27;reviewtext_embedding_63&#x27;, &#x27;reviewtext_embedding_64&#x27;, &#x27;reviewtext_embedding_65&#x27;, &#x27;reviewtext_embedding_66&#x27;, &#x27;reviewtext_embedding_67&#x27;, &#x27;reviewtext_embedding_68&#x27;, &#x27;reviewtext_embedding_69&#x27;, &#x27;reviewtext_embedding_70&#x27;, &#x27;reviewtext_embedding_71&#x27;, &#x27;reviewtext_embedding_72&#x27;, &#x27;reviewtext_embedding_73&#x27;, &#x27;reviewtext_embedding_74&#x27;, &#x27;reviewtext_embedding_75&#x27;, &#x27;reviewtext_embedding_76&#x27;, &#x27;reviewtext_embedding_77&#x27;, &#x27;reviewtext_embedding_78&#x27;, &#x27;reviewtext_embedding_79&#x27;, &#x27;reviewtext_embedding_80&#x27;, &#x27;reviewtext_embedding_81&#x27;, &#x27;reviewtext_embedding_82&#x27;, &#x27;reviewtext_embedding_83&#x27;, &#x27;reviewtext_embedding_84&#x27;, &#x27;reviewtext_embedding_85&#x27;, &#x27;reviewtext_embedding_86&#x27;, &#x27;reviewtext_embedding_87&#x27;, &#x27;reviewtext_embedding_88&#x27;, &#x27;reviewtext_embedding_89&#x27;, &#x27;reviewtext_embedding_90&#x27;, &#x27;reviewtext_embedding_91&#x27;, &#x27;reviewtext_embedding_92&#x27;, &#x27;reviewtext_embedding_93&#x27;, &#x27;reviewtext_embedding_94&#x27;, &#x27;reviewtext_embedding_95&#x27;, &#x27;reviewtext_embedding_96&#x27;, &#x27;reviewtext_embedding_97&#x27;, &#x27;reviewtext_embedding_98&#x27;, &#x27;reviewtext_embedding_99&#x27;, &#x27;reviewtext_embedding_100&#x27;, &#x27;reviewtext_embedding_101&#x27;, &#x27;reviewtext_embedding_102&#x27;, &#x27;reviewtext_embedding_103&#x27;, &#x27;reviewtext_embedding_104&#x27;, &#x27;reviewtext_embedding_105&#x27;, &#x27;reviewtext_embedding_106&#x27;, &#x27;reviewtext_embedding_107&#x27;, &#x27;reviewtext_embedding_108&#x27;, &#x27;reviewtext_embedding_109&#x27;, &#x27;reviewtext_embedding_110&#x27;, &#x27;reviewtext_embedding_111&#x27;, &#x27;reviewtext_embedding_112&#x27;, &#x27;reviewtext_embedding_113&#x27;, &#x27;reviewtext_embedding_114&#x27;, &#x27;reviewtext_embedding_115&#x27;, &#x27;reviewtext_embedding_116&#x27;, &#x27;reviewtext_embedding_117&#x27;, &#x27;reviewtext_embedding_118&#x27;, &#x27;reviewtext_embedding_119&#x27;, &#x27;reviewtext_embedding_120&#x27;, &#x27;reviewtext_embedding_121&#x27;, &#x27;reviewtext_embedding_122&#x27;, &#x27;reviewtext_embedding_123&#x27;, &#x27;reviewtext_embedding_124&#x27;, &#x27;reviewtext_embedding_125&#x27;, &#x27;reviewtext_embedding_126&#x27;, &#x27;reviewtext_embedding_127&#x27;, &#x27;reviewtext_embedding_128&#x27;, &#x27;reviewtext_embedding_129&#x27;, &#x27;reviewtext_embedding_130&#x27;, &#x27;reviewtext_embedding_131&#x27;, &#x27;reviewtext_embedding_132&#x27;, &#x27;reviewtext_embedding_133&#x27;, &#x27;reviewtext_embedding_134&#x27;, &#x27;reviewtext_embedding_135&#x27;, &#x27;reviewtext_embedding_136&#x27;, &#x27;reviewtext_embedding_137&#x27;, &#x27;reviewtext_embedding_138&#x27;, &#x27;reviewtext_embedding_139&#x27;, &#x27;reviewtext_embedding_140&#x27;, &#x27;reviewtext_embedding_141&#x27;, &#x27;reviewtext_embedding_142&#x27;, &#x27;reviewtext_embedding_143&#x27;, &#x27;reviewtext_embedding_144&#x27;, &#x27;reviewtext_embedding_145&#x27;, &#x27;reviewtext_embedding_146&#x27;, &#x27;reviewtext_embedding_147&#x27;, &#x27;reviewtext_embedding_148&#x27;, &#x27;reviewtext_embedding_149&#x27;, &#x27;reviewtext_embedding_150&#x27;, &#x27;reviewtext_embedding_151&#x27;, &#x27;reviewtext_embedding_152&#x27;, &#x27;reviewtext_embedding_153&#x27;, &#x27;reviewtext_embedding_154&#x27;, &#x27;reviewtext_embedding_155&#x27;, &#x27;reviewtext_embedding_156&#x27;, &#x27;reviewtext_embedding_157&#x27;, &#x27;reviewtext_embedding_158&#x27;, &#x27;reviewtext_embedding_159&#x27;, &#x27;reviewtext_embedding_160&#x27;, &#x27;reviewtext_embedding_161&#x27;, &#x27;reviewtext_embedding_162&#x27;, &#x27;reviewtext_embedding_163&#x27;, &#x27;reviewtext_embedding_164&#x27;, &#x27;reviewtext_embedding_165&#x27;, &#x27;reviewtext_embedding_166&#x27;, &#x27;reviewtext_embedding_167&#x27;, &#x27;reviewtext_embedding_168&#x27;, &#x27;reviewtext_embedding_169&#x27;, &#x27;reviewtext_embedding_170&#x27;, &#x27;reviewtext_embedding_171&#x27;, &#x27;reviewtext_embedding_172&#x27;, &#x27;reviewtext_embedding_173&#x27;, &#x27;reviewtext_embedding_174&#x27;, &#x27;reviewtext_embedding_175&#x27;, &#x27;reviewtext_embedding_176&#x27;, &#x27;reviewtext_embedding_177&#x27;, &#x27;reviewtext_embedding_178&#x27;, &#x27;reviewtext_embedding_179&#x27;, &#x27;reviewtext_embedding_180&#x27;, &#x27;reviewtext_embedding_181&#x27;, &#x27;reviewtext_embedding_182&#x27;, &#x27;reviewtext_embedding_183&#x27;, &#x27;reviewtext_embedding_184&#x27;, &#x27;reviewtext_embedding_185&#x27;, &#x27;reviewtext_embedding_186&#x27;, &#x27;reviewtext_embedding_187&#x27;, &#x27;reviewtext_embedding_188&#x27;, &#x27;reviewtext_embedding_189&#x27;, &#x27;reviewtext_embedding_190&#x27;, &#x27;reviewtext_embedding_191&#x27;, &#x27;reviewtext_embedding_192&#x27;, &#x27;reviewtext_embedding_193&#x27;, &#x27;reviewtext_embedding_194&#x27;, &#x27;reviewtext_embedding_195&#x27;, &#x27;reviewtext_embedding_196&#x27;, &#x27;reviewtext_embedding_197&#x27;, &#x27;reviewtext_embedding_198&#x27;, &#x27;reviewtext_embedding_199&#x27;, &#x27;reviewtext_embedding_200&#x27;, &#x27;reviewtext_embedding_201&#x27;, &#x27;reviewtext_embedding_202&#x27;, &#x27;reviewtext_embedding_203&#x27;, &#x27;reviewtext_embedding_204&#x27;, &#x27;reviewtext_embedding_205&#x27;, &#x27;reviewtext_embedding_206&#x27;, &#x27;reviewtext_embedding_207&#x27;, &#x27;reviewtext_embedding_208&#x27;, &#x27;reviewtext_embedding_209&#x27;, &#x27;reviewtext_embedding_210&#x27;, &#x27;reviewtext_embedding_211&#x27;, &#x27;reviewtext_embedding_212&#x27;, &#x27;reviewtext_embedding_213&#x27;, &#x27;reviewtext_embedding_214&#x27;, &#x27;reviewtext_embedding_215&#x27;, &#x27;reviewtext_embedding_216&#x27;, &#x27;reviewtext_embedding_217&#x27;, &#x27;reviewtext_embedding_218&#x27;, &#x27;reviewtext_embedding_219&#x27;, &#x27;reviewtext_embedding_220&#x27;, &#x27;reviewtext_embedding_221&#x27;, &#x27;reviewtext_embedding_222&#x27;, &#x27;reviewtext_embedding_223&#x27;, &#x27;reviewtext_embedding_224&#x27;, &#x27;reviewtext_embedding_225&#x27;, &#x27;reviewtext_embedding_226&#x27;, &#x27;reviewtext_embedding_227&#x27;, &#x27;reviewtext_embedding_228&#x27;, &#x27;reviewtext_embedding_229&#x27;, &#x27;reviewtext_embedding_230&#x27;, &#x27;reviewtext_embedding_231&#x27;, &#x27;reviewtext_embedding_232&#x27;, &#x27;reviewtext_embedding_233&#x27;, &#x27;reviewtext_embedding_234&#x27;, &#x27;reviewtext_embedding_235&#x27;, &#x27;reviewtext_embedding_236&#x27;, &#x27;reviewtext_embedding_237&#x27;, &#x27;reviewtext_embedding_238&#x27;, &#x27;reviewtext_embedding_239&#x27;, &#x27;reviewtext_embedding_240&#x27;, &#x27;reviewtext_embedding_241&#x27;, &#x27;reviewtext_embedding_242&#x27;, &#x27;reviewtext_embedding_243&#x27;, &#x27;reviewtext_embedding_244&#x27;, &#x27;reviewtext_embedding_245&#x27;, &#x27;reviewtext_embedding_246&#x27;, &#x27;reviewtext_embedding_247&#x27;, &#x27;reviewtext_embedding_248&#x27;, &#x27;reviewtext_embedding_249&#x27;, &#x27;reviewtext_embedding_250&#x27;, &#x27;reviewtext_embedding_251&#x27;, &#x27;reviewtext_embedding_252&#x27;, &#x27;reviewtext_embedding_253&#x27;, &#x27;reviewtext_embedding_254&#x27;, &#x27;reviewtext_embedding_255&#x27;, &#x27;reviewtext_embedding_256&#x27;, &#x27;reviewtext_embedding_257&#x27;, &#x27;reviewtext_embedding_258&#x27;, &#x27;reviewtext_embedding_259&#x27;, &#x27;reviewtext_embedding_260&#x27;, &#x27;reviewtext_embedding_261&#x27;, &#x27;reviewtext_embedding_262&#x27;, &#x27;reviewtext_embedding_263&#x27;, &#x27;reviewtext_embedding_264&#x27;, &#x27;reviewtext_embedding_265&#x27;, &#x27;reviewtext_embedding_266&#x27;, &#x27;reviewtext_embedding_267&#x27;, &#x27;reviewtext_embedding_268&#x27;, &#x27;reviewtext_embedding_269&#x27;, &#x27;reviewtext_embedding_270&#x27;, &#x27;reviewtext_embedding_271&#x27;, &#x27;reviewtext_embedding_272&#x27;, &#x27;reviewtext_embedding_273&#x27;, &#x27;reviewtext_embedding_274&#x27;, &#x27;reviewtext_embedding_275&#x27;, &#x27;reviewtext_embedding_276&#x27;, &#x27;reviewtext_embedding_277&#x27;, &#x27;reviewtext_embedding_278&#x27;, &#x27;reviewtext_embedding_279&#x27;, &#x27;reviewtext_embedding_280&#x27;, &#x27;reviewtext_embedding_281&#x27;, &#x27;reviewtext_embedding_282&#x27;, &#x27;reviewtext_embedding_283&#x27;, &#x27;reviewtext_embedding_284&#x27;, &#x27;reviewtext_embedding_285&#x27;, &#x27;reviewtext_embedding_286&#x27;, &#x27;reviewtext_embedding_287&#x27;, &#x27;reviewtext_embedding_288&#x27;, &#x27;reviewtext_embedding_289&#x27;, &#x27;reviewtext_embedding_290&#x27;, &#x27;reviewtext_embedding_291&#x27;, &#x27;reviewtext_embedding_292&#x27;, &#x27;reviewtext_embedding_293&#x27;, &#x27;reviewtext_embedding_294&#x27;, &#x27;reviewtext_embedding_295&#x27;, &#x27;reviewtext_embedding_296&#x27;, &#x27;reviewtext_embedding_297&#x27;, &#x27;reviewtext_embedding_298&#x27;, &#x27;reviewtext_embedding_299&#x27;, &#x27;reviewtext_embedding_300&#x27;, &#x27;reviewtext_embedding_301&#x27;, &#x27;reviewtext_embedding_302&#x27;, &#x27;reviewtext_embedding_303&#x27;, &#x27;reviewtext_embedding_304&#x27;, &#x27;reviewtext_embedding_305&#x27;, &#x27;reviewtext_embedding_306&#x27;, &#x27;reviewtext_embedding_307&#x27;, &#x27;reviewtext_embedding_308&#x27;, &#x27;reviewtext_embedding_309&#x27;, &#x27;reviewtext_embedding_310&#x27;, &#x27;reviewtext_embedding_311&#x27;, &#x27;reviewtext_embedding_312&#x27;, &#x27;reviewtext_embedding_313&#x27;, &#x27;reviewtext_embedding_314&#x27;, &#x27;reviewtext_embedding_315&#x27;, &#x27;reviewtext_embedding_316&#x27;, &#x27;reviewtext_embedding_317&#x27;, &#x27;reviewtext_embedding_318&#x27;, &#x27;reviewtext_embedding_319&#x27;, &#x27;reviewtext_embedding_320&#x27;, &#x27;reviewtext_embedding_321&#x27;, &#x27;reviewtext_embedding_322&#x27;, &#x27;reviewtext_embedding_323&#x27;, &#x27;reviewtext_embedding_324&#x27;, &#x27;reviewtext_embedding_325&#x27;, &#x27;reviewtext_embedding_326&#x27;, &#x27;reviewtext_embedding_327&#x27;, &#x27;reviewtext_embedding_328&#x27;, &#x27;reviewtext_embedding_329&#x27;, &#x27;reviewtext_embedding_330&#x27;, &#x27;reviewtext_embedding_331&#x27;, &#x27;reviewtext_embedding_332&#x27;, &#x27;reviewtext_embedding_333&#x27;, &#x27;reviewtext_embedding_334&#x27;, &#x27;reviewtext_embedding_335&#x27;, &#x27;reviewtext_embedding_336&#x27;, &#x27;reviewtext_embedding_337&#x27;, &#x27;reviewtext_embedding_338&#x27;, &#x27;reviewtext_embedding_339&#x27;, &#x27;reviewtext_embedding_340&#x27;, &#x27;reviewtext_embedding_341&#x27;, &#x27;reviewtext_embedding_342&#x27;, &#x27;reviewtext_embedding_343&#x27;, &#x27;reviewtext_embedding_344&#x27;, &#x27;reviewtext_embedding_345&#x27;, &#x27;reviewtext_embedding_346&#x27;, &#x27;reviewtext_embedding_347&#x27;, &#x27;reviewtext_embedding_348&#x27;, &#x27;reviewtext_embedding_349&#x27;, &#x27;reviewtext_embedding_350&#x27;, &#x27;reviewtext_embedding_351&#x27;, &#x27;reviewtext_embedding_352&#x27;, &#x27;reviewtext_embedding_353&#x27;, &#x27;reviewtext_embedding_354&#x27;, &#x27;reviewtext_embedding_355&#x27;, &#x27;reviewtext_embedding_356&#x27;, &#x27;reviewtext_embedding_357&#x27;, &#x27;reviewtext_embedding_358&#x27;, &#x27;reviewtext_embedding_359&#x27;, &#x27;reviewtext_embedding_360&#x27;, &#x27;reviewtext_embedding_361&#x27;, &#x27;reviewtext_embedding_362&#x27;, &#x27;reviewtext_embedding_363&#x27;, &#x27;reviewtext_embedding_364&#x27;, &#x27;reviewtext_embedding_365&#x27;, &#x27;reviewtext_embedding_366&#x27;, &#x27;reviewtext_embedding_367&#x27;, &#x27;reviewtext_embedding_368&#x27;, &#x27;reviewtext_embedding_369&#x27;, &#x27;reviewtext_embedding_370&#x27;, &#x27;reviewtext_embedding_371&#x27;, &#x27;reviewtext_embedding_372&#x27;, &#x27;reviewtext_embedding_373&#x27;, &#x27;reviewtext_embedding_374&#x27;, &#x27;reviewtext_embedding_375&#x27;, &#x27;reviewtext_embedding_376&#x27;, &#x27;reviewtext_embedding_377&#x27;, &#x27;reviewtext_embedding_378&#x27;, &#x27;reviewtext_embedding_379&#x27;, &#x27;reviewtext_embedding_380&#x27;, &#x27;reviewtext_embedding_381&#x27;, &#x27;reviewtext_embedding_382&#x27;, &#x27;reviewtext_embedding_383&#x27;, &#x27;mean_sentiment_score&#x27;, &#x27;mean_complaint_similarity&#x27;, &#x27;mean_shipping_similarity&#x27;, &#x27;max_complaint_similarity&#x27;, &#x27;shipping_similarity_at_max_complaint&#x27;, &#x27;sentiment_score_at_max_complaint&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;category&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=None)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['item_rank', 'avg_rating',\n",
       "                                                   'min_rating',\n",
       "                                                   'percent_positive',\n",
       "                                                   'percent_negative',\n",
       "                                                   'avg_verified_reviewers',\n",
       "                                                   'product_lifespan',\n",
       "                                                   'num_bots_per_asin',\n",
       "                                                   'unique_reviewer_count',\n",
       "                                                   'avg_reviews_per_day',\n",
       "                                                   'reviews_per_product',\n",
       "                                                   'avg_review_length_words',\n",
       "                                                   'summary_embedding_0',\n",
       "                                                   'sum...\n",
       "                                                   'summary_embedding_8',\n",
       "                                                   'summary_embedding_9',\n",
       "                                                   'summary_embedding_10',\n",
       "                                                   'summary_embedding_11',\n",
       "                                                   'summary_embedding_12',\n",
       "                                                   'summary_embedding_13',\n",
       "                                                   'summary_embedding_14',\n",
       "                                                   'summary_embedding_15',\n",
       "                                                   'summary_embedding_16',\n",
       "                                                   'summary_embedding_17', ...]),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['category'])])),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(class_weight='balanced', penalty=None))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.fit(train_df, train_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0fa0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_pipeline.predict(val_df)\n",
    "probs = model_pipeline.predict_proba(val_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef484084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importance from the pipeline log reg\n",
    "logreg = model_pipeline.named_steps['logreg']\n",
    "\n",
    "# get preprocessed columns\n",
    "preprocessor = model_pipeline.named_steps['preprocessing']\n",
    "\n",
    "# Get names from each transformer\n",
    "num_features = preprocessor.named_transformers_['num'].get_feature_names_out(numeric_cols)\n",
    "cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine all feature names\n",
    "all_features = np.concatenate([num_features, cat_features])\n",
    "\n",
    "# get coefficients for feature importance\n",
    "coefficients = pd.Series(logreg.coef_[0], index=all_features)\n",
    "coefficients = coefficients.sort_values(key=np.abs, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71bb1d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_Games                          -3.850213\n",
       "category_Party Supplies                 -2.309550\n",
       "category_Tricycles, Scooters & Wagons    2.305755\n",
       "category_Baby & Toddler Toys             1.463390\n",
       "category_Dolls & Accessories             1.341731\n",
       "category_Sports & Outdoor Play           1.337283\n",
       "category_Building Toys                  -1.266354\n",
       "category_Arts & Crafts                   1.229312\n",
       "category_Hobbies                        -1.157462\n",
       "category_Puzzles                        -1.073150\n",
       "category_Action Figures & Statues       -1.057455\n",
       "reviewtext_embedding_354                -0.959197\n",
       "reviewtext_embedding_223                -0.919786\n",
       "item_rank                               -0.896850\n",
       "reviewtext_embedding_367                 0.888946\n",
       "reviewtext_embedding_119                 0.864387\n",
       "summary_embedding_217                    0.852088\n",
       "category_Grown-Up Toys                  -0.841802\n",
       "unique_reviewer_count                    0.810886\n",
       "reviewtext_embedding_192                 0.801326\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95f39a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, y_true, y_pred, y_prob):\n",
    "    return {\n",
    "        model_name: {\n",
    "        #\"report\": classification_report(y_true, y_pred, output_dict=True),\n",
    "        \"conf_mat\": confusion_matrix(y_true, y_pred),\n",
    "        \"prec\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"pr_auc\": average_precision_score(y_true, y_prob)\n",
    "    }}\n",
    "    \n",
    "all_results = {}\n",
    "all_results.update(evaluate_model(\"LogisticRegression\", y_true=val_y, y_pred = preds, y_prob = probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97eb3158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'conf_mat': array([[21236,  2764],\n",
       "         [   84,    80]]),\n",
       "  'prec': 0.02812939521800281,\n",
       "  'recall': 0.4878048780487805,\n",
       "  'f1': 0.05319148936170213,\n",
       "  'pr_auc': np.float64(0.025077464564341696)}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194ec7c",
   "metadata": {},
   "source": [
    "Remove some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5fe1b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['category_games',\n",
    "                     'item_rank',\n",
    "                     'unique_reviewer_count',\n",
    "                     'max_complaint_similarity',\n",
    "                     'avg_review_length_words'\n",
    "                     ]\n",
    "\n",
    "numeric_cols = ['item_rank', 'unique_reviewer_count', 'max_complaint_similarity', 'avg_review_length_words']\n",
    "categorical_cols = ['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6214fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the pipeline\n",
    "model_pipe_red_feat = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('logreg', LogisticRegression(penalty=None, class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "# filter train and validation sets by selected features\n",
    "train_red_feat_df = train_df[numeric_cols + categorical_cols]\n",
    "val_red_feat_df = val_df[numeric_cols + categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24d9e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe_red_feat.fit(train_red_feat_df, train_y)\n",
    "pred_red_feat = model_pipe_red_feat.predict(val_red_feat_df)\n",
    "probs_red_feat = model_pipe_red_feat.predict_proba(val_red_feat_df)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0d13f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.update(evaluate_model(\"LogisticRegression_red_feat\", y_true=val_y,\n",
    "                                  y_pred = pred_red_feat,\n",
    "                                  y_prob = probs_red_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d6963d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'conf_mat': array([[21236,  2764],\n",
       "         [   84,    80]]),\n",
       "  'prec': 0.02812939521800281,\n",
       "  'recall': 0.4878048780487805,\n",
       "  'f1': 0.05319148936170213,\n",
       "  'pr_auc': np.float64(0.025077464564341696)},\n",
       " 'LogisticRegression_red_feat': {'conf_mat': array([[18258,  5742],\n",
       "         [   40,   124]]),\n",
       "  'prec': 0.02113876576883737,\n",
       "  'recall': 0.7560975609756098,\n",
       "  'f1': 0.041127694859038146,\n",
       "  'pr_auc': np.float64(0.04225383796728305)}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "PCA()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
