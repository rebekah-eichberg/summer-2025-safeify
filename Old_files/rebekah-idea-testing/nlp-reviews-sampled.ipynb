{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5257000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/rebekaheichberg/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')       \n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt_tab')  \n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helper_functions import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a928e95f",
   "metadata": {},
   "source": [
    "Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8768d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Recall data\n",
    "\n",
    "# Paths to all three files\n",
    "recall_files = [\n",
    "    \"../Data/Current Version of Toys Incidence+Recall/Toysandchildren_ArtsandCrafts.csv\",\n",
    "    \"../Data/Current Version of Toys Incidence+Recall/Toysandchildren_Riding_Toys.csv\",\n",
    "    \"../Data/Current Version of Toys Incidence+Recall/Toysandchildren_Toys.csv\"\n",
    "]\n",
    "\n",
    "recall_dfs = [load_clean_csv(path) for path in recall_files]\n",
    "recalls_df = pd.concat(recall_dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in reviews data\n",
    "reviews_df = pd.read_pickle('reviews_raw.pkl')\n",
    "reviews_df['asin'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273868d8",
   "metadata": {},
   "source": [
    "Embed the Incident Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcde81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model to create embeddings on incident description text\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the recalls data, embed the incident description\n",
    "combined_indicent_text = \" \".join(recalls_df['Incident Description'].dropna().tolist())\n",
    "incident_desc_embedding = model.encode(combined_indicent_text)\n",
    "incident_desc_embedding = np.array(incident_desc_embedding).reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c83aa7",
   "metadata": {},
   "source": [
    "From Incident Description, we generate a dictionary of words and their frequences. Then use LLM to extract negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "incidents = recalls_df['Incident Description'].dropna().astype(str)\n",
    "all_tokens = incidents.apply(preprocess)\n",
    "\n",
    "# Flatten to single list of tokens\n",
    "flattened_tokens = [token for sublist in all_tokens for token in sublist]\n",
    "word_freq = Counter(flattened_tokens)\n",
    "top_words = word_freq.most_common(20)\n",
    "print(top_words)\n",
    "\n",
    "# Give this list to a LLM to extract negative words\n",
    "list(word_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c391b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat gpt returns the negative words from word_freq\n",
    "negative_words = [\n",
    "    'choke', 'hazard', 'dangerous', 'danger', 'dermatitis', 'bother',\n",
    "    'accidentally', 'ingest', 'notorious', 'toxic', 'warn', 'cause',\n",
    "    'allergic', 'reaction', 'rash', 'sensitization', 'occur',\n",
    "    'seek', 'medical', 'die', 'poison', 'elevated', 'burn', 'urgent',\n",
    "    'treatment', 'pinch', 'pinched', 'slice', 'lacerate', 'moldy',\n",
    "    'waste', 'black', 'spot', 'bleed', 'miss', 'sharp', 'metal',\n",
    "    'damage', 'difficulty', 'injure', 'inconvenience', 'serious',\n",
    "    'return', 'disagree', 'concern', 'broken', 'shatter', 'remove',\n",
    "    'unsafe', 'terrible', 'odor', 'infuriate', 'infection', 'irritation',\n",
    "    'cough', 'irritate', 'headache', 'chemical', 'blister', 'bleeding',\n",
    "    'sick', 'asthma', 'attack', 'pain', 'scar', 'nasty', 'impact',\n",
    "    'accident', 'penetrate', 'trapping', 'ignite', 'overheat',\n",
    "    'fire', 'fail', 'explode', 'burning', 'puncture', 'swollen',\n",
    "    'wound', 'injury', 'hurt', 'sore', 'contaminate', 'vomit', 'bleed',\n",
    "    'allergy', 'toxic', 'deadly', 'severe', 'dyshidrotic', 'eczema',\n",
    "    'bacterial', 'disapointing', 'poorly', 'redness', 'burnt',\n",
    "    'complain', 'bad', 'dangerously', 'emergency', 'hospital'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486af372",
   "metadata": {},
   "source": [
    "Take a SAMPLE of the reviews data to check the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a smaller reviews dataframe\n",
    "reviews_sample_df = reviews_df.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ff25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment model\n",
    "model_name = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_sent = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e42713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment_weight(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model_sent(**inputs).logits\n",
    "    probs = softmax(logits, dim=1).numpy().flatten()\n",
    "    return probs[0]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should we be dropping duplicates?\n",
    "reviews_sample_df[reviews_sample_df.duplicated(['asin', 'reviewText', 'summary'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na in reviewtext, asin and summary column\n",
    "reviews_sample_df = reviews_sample_df[['asin', 'reviewText', 'summary' ,'overall']].copy()\n",
    "reviews_sample_df = reviews_sample_df.dropna(subset=['asin','reviewText', 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf59881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip possible leading or trailing white space\n",
    "reviews_model_df = reviews_sample_df[reviews_sample_df['reviewText'].str.strip() != '']\n",
    "reviews_model_df = reviews_model_df[reviews_model_df['summary'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ed5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming reviews_model_df['summary'] contains review titles\n",
    "reviews_model_df['sentiment_weight'] = reviews_model_df['summary'].apply(compute_sentiment_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da6cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the summary\n",
    "summary_embeddings = model.encode(\n",
    "    reviews_model_df['summary'].tolist(),\n",
    "    batch_size=32,    #32, 64, 128 based on memory           \n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True        \n",
    ")\n",
    "# reviews_model_df['summary_embeddings'] = [vec for vec in summary_embeddings]\n",
    "reviews_model_df['summary_embeddings'] = list(summary_embeddings)\n",
    "# summary_embeddings = np.array(summary_embeddings)\n",
    "# summary_embeddings = np.vstack(summary_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_embedding(group):\n",
    "    weights = np.array(group['sentiment_weight'].tolist())\n",
    "    embeddings = np.stack(group['summary_embeddings'].tolist())\n",
    "    if weights.sum() == 0:\n",
    "        weights = np.ones_like(weights)\n",
    "    return np.average(embeddings, axis=0, weights=weights)\n",
    "\n",
    "product_embeddings = (\n",
    "    reviews_model_df\n",
    "    .groupby('asin')\n",
    "    .apply(weighted_avg_embedding)\n",
    ")\n",
    "\n",
    "product_embedding_matrix = np.vstack(product_embeddings.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5be2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_incident_text = \" \".join(recalls_df['Incident Description'].dropna().tolist())\n",
    "\n",
    "\n",
    "# incident_desc_embedding = model.encode(\n",
    "#     [combined_incident_text],  \n",
    "#     convert_to_numpy=True\n",
    "# )\n",
    "\n",
    "\n",
    "# incident_desc_embedding = np.array(incident_desc_embedding).reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # Compute cosine similarity\n",
    "# similarities = cosine_similarity(product_embedding_matrix, incident_desc_embedding)\n",
    "\n",
    "# # Format as DataFrame\n",
    "# similarity_df = pd.DataFrame({\n",
    "#     'asin': product_embeddings.index,\n",
    "#     'similarity_to_incidents': similarities.flatten()\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09eef5e",
   "metadata": {},
   "source": [
    "Review Text Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make reviewText embeddings# embed the summary\n",
    "reviewtext_embeddings = model.encode(\n",
    "    reviews_model_df['reviewText'].tolist(),\n",
    "    batch_size=32,    #32, 64, 128 based on memory           \n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True        \n",
    ")\n",
    "# reviews_model_df['summary_embeddings'] = [vec for vec in summary_embeddings]\n",
    "reviews_model_df['reviewtext_embeddings'] = list(reviewtext_embeddings)\n",
    "# summary_embeddings = np.array(summary_embeddings)\n",
    "# summary_embeddings = np.vstack(summary_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac999eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take cosine similarity between reviews and the incident description embedding\n",
    "review_similarities = cosine_similarity(incident_desc_embedding, reviewtext_embeddings)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the cosine similarities between review and incidents on the main df\n",
    "reviews_model_df['review_cosine_sim'] = review_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_model_df = reviews_model_df.sort_values('review_cosine_sim', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8614f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_model_df[['reviewText', 'summary', 'review_cosine_sim']].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d29b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of reviews per product\n",
    "reviews_model_df.groupby('asin')['reviewText'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56cb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_df = reviews_model_df.groupby('asin')['review_cosine_sim'].agg(\n",
    "    mean_similarity = 'mean',\n",
    "    max_similarity = 'max'\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af16565",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aedb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25be072",
   "metadata": {},
   "source": [
    "Methods We are not Using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c13e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way is to do thematic classification\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import re\n",
    "cluster = 5\n",
    "test_embeddings = model.encode(recalls_df['Incident Description'].tolist())\n",
    "kmeans = KMeans(n_clusters=cluster)\n",
    "recalls_df['cluster'] = kmeans.fit_predict(test_embeddings)\n",
    "\n",
    "for cluster_num in range(cluster):\n",
    "    sample_texts = recalls_df[recalls_df['cluster'] == cluster_num]['Incident Description']\n",
    "\n",
    "def get_top_words(texts, n=cluster):\n",
    "    all_words = ' '.join(texts).lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', all_words)\n",
    "    stop_words = set(stopwords.words('english'))  \n",
    "    filtered_words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words and len(w) > 2]\n",
    "    common_words = Counter(filtered_words).most_common(n)\n",
    "    return [w[0] for w in common_words]\n",
    "\n",
    "for cluster_num in range(cluster):\n",
    "    texts = recalls_df[recalls_df['cluster'] == cluster_num]['Incident Description']\n",
    "    print(f\"\\nTop words for cluster {cluster_num}: {get_top_words(texts)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ab6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(incidents)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=40, random_state=0)\n",
    "lda.fit(X)\n",
    "\n",
    "# Get keywords per topic\n",
    "words = vectorizer.get_feature_names_out()\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    top_words = [words[i] for i in topic.argsort()[-10:]]\n",
    "    print(f\"Topic {i+1}: {top_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576ec59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
