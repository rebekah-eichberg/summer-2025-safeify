{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent   \n",
    "sys.path.insert(0, str(project_root / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893724b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from prob_cal_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0488ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"The `cv='prefit'` option is deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d3fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the data\n",
    "train_df = pd.read_parquet(\"../train_final_v3.parquet\")\n",
    "val_df = pd.read_parquet(\"../validationA_v3.parquet\")\n",
    "cal_df = pd.read_parquet(\"../validationB_v3.parquet\")\n",
    "test_df = pd.read_parquet(\"../test_v3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11548ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shapes of the dataframes\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(cal_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the target from the features\n",
    "X_train, y_train = split_features_target(train_df)\n",
    "X_val, y_val = split_features_target(val_df)\n",
    "X_cal, y_cal = split_features_target(cal_df)\n",
    "X_test, y_test = split_features_target(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa919f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [X_train, X_val, X_cal, X_test]\n",
    "\n",
    "for df in dfs:\n",
    "    # Calculate review_span in days\n",
    "    df['review_span'] = (df['max_date'] - df['min_date']).dt.days\n",
    "    df.drop(['min_date', 'max_date'], axis=1, inplace=True)\n",
    "    \n",
    "    # Convert missing_price to int\n",
    "    df['missing_price'] = df['missing_price'].astype(int)\n",
    "    \n",
    "    # Calculate product_lifespan in days\n",
    "    df['product_lifespan_days'] = df['product_lifespan'].dt.days\n",
    "    df.drop('product_lifespan', axis=1, inplace=True)\n",
    "    \n",
    "    df.drop(['percent_positive', 'percent_negative', 'unique_reviewer_count', 'review_span'], axis=1, inplace=True)\n",
    "\n",
    "# Print shapes\n",
    "print(f\"X_train: {X_train.shape}, X_val: {X_val.shape}, X_cal: {X_cal.shape}, X_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910323b",
   "metadata": {},
   "source": [
    "Preprocessing PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all of the data \n",
    "preprocessor = make_transformer(X_train, 0.95, 0.95)\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "X_cal_proc = preprocessor.transform(X_cal)\n",
    "X_test_proc = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537dfb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Types\n",
    "num_cols = [c for c in X_train_proc.columns if c.startswith(\"num__\")]\n",
    "cat_cols       = [c for c in X_train_proc.columns if c.startswith(\"cat__\")]\n",
    "rev_cols       = [c for c in X_train_proc.columns if c.startswith(\"rev__\")]\n",
    "sum_cols       = [c for c in X_train_proc.columns if c.startswith(\"sum__\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9a371",
   "metadata": {},
   "source": [
    "Models to Fit **Without** Categorical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the models found in hyperparameter tuning\n",
    "model_2_wo_cat = LogisticRegression(penalty='l2', solver='newton-cg', C=0.1, class_weight={0: 1, 1: 250}, max_iter=1000, random_state=42) # best overall\n",
    "model_7_wo_cat = RandomForestClassifier(n_estimators=300,\n",
    "                                 class_weight={0:1.0, 1:250.0},\n",
    "                                 max_depth=5,\n",
    "                                 min_samples_split=10,\n",
    "                                 min_samples_leaf=3,\n",
    "                                 max_features='log2',\n",
    "                                 random_state=42)\n",
    "model_8_wo_cat = XGBClassifier(\n",
    "    n_estimators=300, max_depth=5, learning_rate=0.01,\n",
    "    subsample=0.6, colsample_bytree=0.6,\n",
    "    reg_alpha=0.5, reg_lambda=1.0,\n",
    "    scale_pos_weight=400.0,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42, n_jobs=-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d600d",
   "metadata": {},
   "source": [
    "Models to Fit **With** Categorical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the models found in hyperparameter tuning\n",
    "model_4 = LogisticRegression(penalty='l2', solver='newton-cg',\n",
    "                             C=1.0, class_weight='balanced', max_iter=1000, random_state=42)\n",
    "model_5 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, class_weight={\n",
    "                             0: 1, 1: 250}, max_iter=1000, random_state=42)  # best overall\n",
    "model_6 = LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, class_weight={\n",
    "                             0: 1, 1: 400}, max_iter=1000, random_state=42)\n",
    "model_7 = RandomForestClassifier(n_estimators=300,\n",
    "                                 class_weight={0: 1.0, 1: 250.0},\n",
    "                                 max_depth=5,\n",
    "                                 min_samples_split=10,\n",
    "                                 min_samples_leaf=3,\n",
    "                                 max_features='log2',\n",
    "                                 random_state=42)\n",
    "model_8 = XGBClassifier(\n",
    "    n_estimators=300, max_depth=5, learning_rate=0.01,\n",
    "    subsample=0.6, colsample_bytree=0.6,\n",
    "    reg_alpha=0.5, reg_lambda=1.0,\n",
    "    scale_pos_weight=400.0,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42, n_jobs=-3)\n",
    "\n",
    "model_9 = RandomForestClassifier(n_estimators=300,\n",
    "                                 class_weight='balanced',\n",
    "                                 max_depth=5,\n",
    "                                 min_samples_split=10,\n",
    "                                 min_samples_leaf=3,\n",
    "                                 max_features='log2',\n",
    "                                 random_state=42)\n",
    "\n",
    "model_10 = XGBClassifier(\n",
    "    n_estimators=300, max_depth=3, learning_rate=0.05,\n",
    "    subsample=0.6, colsample_bytree=1.0,\n",
    "    reg_alpha=0.0, reg_lambda=0.5,\n",
    "    scale_pos_weight=250.0,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42, n_jobs=-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de87c1",
   "metadata": {},
   "source": [
    "Train the Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop categorical columns\n",
    "X_train_wo_cat_proc = X_train_proc.drop(columns=cat_cols)\n",
    "X_val_wo_cat_proc = X_val_proc.drop(columns=cat_cols)\n",
    "X_cal_wo_cat_proc = X_cal_proc.drop(columns=cat_cols)\n",
    "X_test_wo_cat_proc = X_test_proc.drop(columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3958a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit models\n",
    "# models without cat_cols\n",
    "model_2_wo_cat.fit(X_train_wo_cat_proc, y_train)\n",
    "model_7_wo_cat.fit(X_train_wo_cat_proc, y_train)\n",
    "model_8_wo_cat.fit(X_train_wo_cat_proc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9561a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit models\n",
    "# models with cat_cols\n",
    "model_4.fit(X_train_proc, y_train)\n",
    "model_5.fit(X_train_proc, y_train)\n",
    "model_6.fit(X_train_proc, y_train)\n",
    "model_7.fit(X_train_proc, y_train)\n",
    "model_8.fit(X_train_proc, y_train)\n",
    "model_9.fit(X_train_proc, y_train)\n",
    "model_10.fit(X_train_proc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12b172",
   "metadata": {},
   "source": [
    "Reliability Curves and Histograms **Before** Probability Calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e189d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier with Categories\n",
    "plot_calibration_and_error_distributions_before_true_cal(\n",
    "    y_true=y_val,\n",
    "    models=[model_5, model_7, model_8],\n",
    "    X=X_val_proc,\n",
    "    threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e90743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier Without Categories\n",
    "plot_calibration_and_error_distributions_before_true_cal(\n",
    "    y_true=y_val,\n",
    "    models=[model_2_wo_cat, model_7_wo_cat, model_8_wo_cat],\n",
    "    X=X_val_wo_cat_proc,\n",
    "    threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f50461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced model\n",
    "plot_calibration_and_error_distributions_before_true_cal(\n",
    "    y_true=y_val,\n",
    "    models=model_4,\n",
    "    X=X_val_proc,\n",
    "    threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6095a6",
   "metadata": {},
   "source": [
    "Calibrate the Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap already-fitted model\n",
    "cal_model_2_wo_cat = CalibratedClassifierCV(estimator=model_2_wo_cat, method='sigmoid', cv='prefit')\n",
    "cal_model_7_wo_cat = CalibratedClassifierCV(estimator=model_7_wo_cat, method='sigmoid', cv='prefit')\n",
    "cal_model_8_wo_cat = CalibratedClassifierCV(estimator=model_8_wo_cat, method='sigmoid', cv='prefit')\n",
    "\n",
    "cal_model_4 = CalibratedClassifierCV(estimator=model_4, method='sigmoid', cv='prefit')\n",
    "cal_model_5 = CalibratedClassifierCV(estimator=model_5, method='sigmoid', cv='prefit')\n",
    "cal_model_6 = CalibratedClassifierCV(estimator=model_6, method='sigmoid', cv='prefit')\n",
    "cal_model_7 = CalibratedClassifierCV(estimator=model_7, method='sigmoid', cv='prefit')\n",
    "cal_model_8 = CalibratedClassifierCV(estimator=model_8, method='sigmoid', cv='prefit' )\n",
    "cal_model_9 = CalibratedClassifierCV(estimator=model_9, method='sigmoid', cv='prefit' )\n",
    "cal_model_10 = CalibratedClassifierCV(estimator=model_10, method='sigmoid', cv='prefit' )\n",
    "\n",
    "\n",
    "# fit calibration model on calibration set\n",
    "cal_model_4.fit(X_cal_proc, y_cal)\n",
    "cal_model_5.fit(X_cal_proc, y_cal)\n",
    "cal_model_6.fit(X_cal_proc, y_cal)\n",
    "cal_model_7.fit(X_cal_proc, y_cal)\n",
    "cal_model_8.fit(X_cal_proc, y_cal)\n",
    "cal_model_9.fit(X_cal_proc, y_cal)\n",
    "cal_model_10.fit(X_cal_proc, y_cal)\n",
    "cal_model_2_wo_cat.fit(X_cal_wo_cat_proc, y_cal)\n",
    "cal_model_7_wo_cat.fit(X_cal_wo_cat_proc, y_cal)\n",
    "cal_model_8_wo_cat.fit(X_cal_wo_cat_proc, y_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf5031",
   "metadata": {},
   "source": [
    "Manual 'Voting' Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7d9c1",
   "metadata": {},
   "source": [
    "**With** Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting classifier with categories\n",
    "plot_calibration_and_class_distributions(\n",
    "    [cal_model_5, cal_model_7, cal_model_8],\n",
    "    X_test_proc,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab71838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear scale plot (zoom near 0)\n",
    "plot_high_res_reliability_and_hist(models=[cal_model_5, cal_model_7, cal_model_8],\n",
    "                                   X=X_test_proc,\n",
    "                                   y_true=y_test,\n",
    "                                   log_scale=False)\n",
    "\n",
    "# Log scale plot\n",
    "plot_high_res_reliability_and_hist(models=[cal_model_5, cal_model_7, cal_model_8],\n",
    "                                   X=X_test_proc,\n",
    "                                   y_true=y_test,\n",
    "                                   log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a2867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced model with categories\n",
    "plot_calibration_and_class_distributions(\n",
    "    cal_model_4,\n",
    "    X_test_proc,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72745ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear scale plot (zoom near 0)\n",
    "plot_high_res_reliability_and_hist(models=cal_model_4,\n",
    "                                   X=X_test_proc,\n",
    "                                   y_true=y_test,\n",
    "                                   log_scale=False)\n",
    "\n",
    "# Log scale plot\n",
    "plot_high_res_reliability_and_hist(models=cal_model_4,\n",
    "                                   X=X_test_proc,\n",
    "                                   y_true=y_test,\n",
    "                                   log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afcd860",
   "metadata": {},
   "source": [
    "**Without** Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b092d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting classifier without categories\n",
    "plot_calibration_and_class_distributions(\n",
    "    [cal_model_2_wo_cat, cal_model_7_wo_cat, cal_model_8_wo_cat],\n",
    "    X_test_wo_cat_proc,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933653c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear scale plot (zoom near 0)\n",
    "plot_high_res_reliability_and_hist(models=[cal_model_5, cal_model_7, cal_model_8],\n",
    "                                   X=X_test_proc,\n",
    "                                   y_true=y_test,\n",
    "                                   log_scale=False)\n",
    "\n",
    "# Log scale plot\n",
    "plot_high_res_reliability_and_hist(models=[cal_model_5, cal_model_7, cal_model_8],\n",
    "                                   X=X_test_proc,\n",
    "                                   y_true=y_test,\n",
    "                                   log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc242115",
   "metadata": {},
   "source": [
    "Anamoly Detection With Voting Classifier With Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef213127",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [cal_model_5, cal_model_7, cal_model_8]\n",
    "proba_list = [model.predict_proba(X_test_proc) for model in models]\n",
    "avg_proba = sum(proba_list) / len(proba_list)\n",
    "proba_class1 = avg_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability distribution of all products\n",
    "sns.histplot(avg_proba[:, 1])\n",
    "#plt.xscale('log')\n",
    "plt.xlim(0, 0.05) \n",
    "plt.xlabel('Probability')\n",
    "plt.title('Probability Distribution (Anomaly Scores) After Model Probability Calibration')\n",
    "\n",
    "# Add vertical dotted line at x = 1/146\n",
    "plt.axvline(x=1/146, color='red', linestyle=':', linewidth=2, label = 'Threshold')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'proba_class1': proba_class1\n",
    "})\n",
    "\n",
    "# Filter to only true class = 0\n",
    "df_negatives = df[df['y_true'] == 0]\n",
    "\n",
    "# set anomaly threshold\n",
    "threshold = df_negatives['proba_class1'].quantile(0.90)\n",
    "\n",
    "# flag anomalies\n",
    "anomalies = df_negatives[df_negatives['proba_class1'] > threshold]\n",
    "\n",
    "print(f\"Anomaly threshold (90th percentile among true class 0): {threshold:.4f}\")\n",
    "print(f\"Number of flagged anomalies: {len(anomalies)}\")\n",
    "\n",
    "# plot \n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_negatives['proba_class1'], bins=50, kde=True, color='steelblue', edgecolor='black', label='P(class=1) | y_true = 0')\n",
    "plt.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'90th percentile = {threshold:.3f}')\n",
    "plt.axvspan(threshold, df_negatives['proba_class1'].max(), color='red', alpha=0.2, label='Anomalies')\n",
    "\n",
    "plt.title('Anomaly Detection: High P(class=1) among True Class 0')\n",
    "plt.xlabel('Predicted Probability of Class 1')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee41a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
